# 1 "pipeline.cu"
# 35 "/usr/include/c++/4.8/exception" 3
#pragma GCC visibility push ( default )
# 149 "/usr/include/c++/4.8/exception" 3
#pragma GCC visibility pop
# 42 "/usr/include/c++/4.8/new" 3
#pragma GCC visibility push ( default )
# 120 "/usr/include/c++/4.8/new" 3
#pragma GCC visibility pop
# 1424 "/usr/local/cuda-7.0//include/driver_types.h"
struct CUstream_st;
# 180 "/usr/include/libio.h" 3
enum __codecvt_result {

__codecvt_ok,
__codecvt_partial,
__codecvt_error,
__codecvt_noconv};
# 245 "/usr/include/libio.h" 3
struct _IO_FILE;
# 51 "/usr/include/x86_64-linux-gnu/bits/waitflags.h" 3
enum idtype_t {
P_ALL,
P_PID,
P_PGID};
# 190 "/usr/include/math.h" 3
enum _ZUt_ {
FP_NAN,


FP_INFINITE,


FP_ZERO,


FP_SUBNORMAL,


FP_NORMAL};
# 302 "/usr/include/math.h" 3
enum _LIB_VERSION_TYPE {
_IEEE_ = (-1),
_SVID_,
_XOPEN_,
_POSIX_,
_ISOC_};
# 128 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt9__is_voidIvEUt_E { _ZNSt9__is_voidIvE7__valueE = 1};
# 148 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIbEUt_E { _ZNSt12__is_integerIbE7__valueE = 1};
# 155 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIcEUt_E { _ZNSt12__is_integerIcE7__valueE = 1};
# 162 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIaEUt_E { _ZNSt12__is_integerIaE7__valueE = 1};
# 169 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIhEUt_E { _ZNSt12__is_integerIhE7__valueE = 1};
# 177 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIwEUt_E { _ZNSt12__is_integerIwE7__valueE = 1};
# 201 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIsEUt_E { _ZNSt12__is_integerIsE7__valueE = 1};
# 208 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerItEUt_E { _ZNSt12__is_integerItE7__valueE = 1};
# 215 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIiEUt_E { _ZNSt12__is_integerIiE7__valueE = 1};
# 222 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIjEUt_E { _ZNSt12__is_integerIjE7__valueE = 1};
# 229 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIlEUt_E { _ZNSt12__is_integerIlE7__valueE = 1};
# 236 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerImEUt_E { _ZNSt12__is_integerImE7__valueE = 1};
# 243 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIxEUt_E { _ZNSt12__is_integerIxE7__valueE = 1};
# 250 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIyEUt_E { _ZNSt12__is_integerIyE7__valueE = 1};
# 268 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt13__is_floatingIfEUt_E { _ZNSt13__is_floatingIfE7__valueE = 1};
# 275 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt13__is_floatingIdEUt_E { _ZNSt13__is_floatingIdE7__valueE = 1};
# 282 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt13__is_floatingIeEUt_E { _ZNSt13__is_floatingIeE7__valueE = 1};
# 358 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt9__is_charIcEUt_E { _ZNSt9__is_charIcE7__valueE = 1};
# 366 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt9__is_charIwEUt_E { _ZNSt9__is_charIwE7__valueE = 1};
# 381 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt9__is_byteIcEUt_E { _ZNSt9__is_byteIcE7__valueE = 1};
# 388 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt9__is_byteIaEUt_E { _ZNSt9__is_byteIaE7__valueE = 1};
# 395 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt9__is_byteIhEUt_E { _ZNSt9__is_byteIhE7__valueE = 1};
# 138 "/usr/include/c++/4.8/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIeEUt_E { _ZNSt12__is_integerIeE7__valueE}; enum _ZNSt12__is_integerIdEUt_E { _ZNSt12__is_integerIdE7__valueE}; enum _ZNSt12__is_integerIfEUt_E { _ZNSt12__is_integerIfE7__valueE};
# 153 "/usr/include/x86_64-linux-gnu/bits/mathinline.h" 3
union _ZZ10__signbitlEUt_;
# 212 "/usr/lib/gcc/x86_64-linux-gnu/4.8/include/stddef.h" 3
typedef unsigned long size_t;
#include "crt/host_runtime.h"
# 135 "/usr/include/x86_64-linux-gnu/bits/types.h" 3
typedef long __clock_t;
# 59 "/usr/include/time.h" 3
typedef __clock_t clock_t;
# 48 "/usr/include/stdio.h" 3
typedef struct _IO_FILE FILE;
# 2 "instructions.h"
typedef unsigned UINT;
typedef int INT;
typedef float FLOAT;
typedef double DOUBLE;
# 153 "/usr/include/x86_64-linux-gnu/bits/mathinline.h" 3
union _ZZ10__signbitlEUt_ { long double __l; int __i[3];};
void *memcpy(void*, const void*, size_t); void *memset(void*, int, size_t);
# 866 "/usr/local/cuda-7.0//include/cuda_runtime_api.h"
extern enum cudaError cudaThreadSynchronize(void);
# 1079 "/usr/local/cuda-7.0//include/cuda_runtime_api.h"
extern enum cudaError cudaGetLastError(void);
# 1150 "/usr/local/cuda-7.0//include/cuda_runtime_api.h"
extern const char *cudaGetErrorString(enum cudaError);
# 2776 "/usr/local/cuda-7.0//include/cuda_runtime_api.h"
extern enum cudaError cudaConfigureCall(struct dim3, struct dim3, size_t, struct CUstream_st *);
# 2957 "/usr/local/cuda-7.0//include/cuda_runtime_api.h"
extern enum cudaError cudaMalloc(void **, size_t);
# 3094 "/usr/local/cuda-7.0//include/cuda_runtime_api.h"
extern enum cudaError cudaFree(void *);
# 3987 "/usr/local/cuda-7.0//include/cuda_runtime_api.h"
extern enum cudaError cudaMemcpy(void *, const void *, size_t, enum cudaMemcpyKind);
# 85 "/usr/include/x86_64-linux-gnu/bits/stdio2.h" 3
extern int __fprintf_chk(FILE *__restrict__, int, const char *__restrict__, ...);

extern int __printf_chk(int, const char *__restrict__, ...);
# 202 "pipeline.cu"
extern void _Z16measure_pipelinev(void);
extern int __cudaSetupArgSimple();
extern int __cudaLaunch();
extern void __nv_dummy_param_ref();
extern void __nv_save_fatbinhandle_for_managed_rt();
extern int __cudaRegisterEntry();
extern int __cudaRegisterBinary();
static void __sti___16_pipeline_cpp1_ii_40ef163b(void) __attribute__((__constructor__));
# 170 "/usr/include/stdio.h" 3
extern struct _IO_FILE *stderr;
# 202 "pipeline.cu"
void _Z16measure_pipelinev(void)
{

 int __cuda_local_var_43172_12_const_kernel_ops;
 unsigned __cuda_local_var_43173_15_non_const_ts[2048];
 unsigned *__cuda_local_var_43174_16_non_const_d_ts;
 unsigned *__cuda_local_var_43175_16_non_const_d_out;


 struct dim3 __cuda_local_var_43178_11_non_const_Db;
 struct dim3 __cuda_local_var_43179_11_non_const_Dg;
# 205 "pipeline.cu"
__cuda_local_var_43172_12_const_kernel_ops = 256;
# 211 "pipeline.cu"
{
# 421 "/usr/local/cuda-7.0//include/vector_types.h"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (__cuda_local_var_43178_11_non_const_Db.y) = 1U; (__cuda_local_var_43178_11_non_const_Db.z) = 1U;
# 211 "pipeline.cu"
}
{
# 421 "/usr/local/cuda-7.0//include/vector_types.h"
(__cuda_local_var_43179_11_non_const_Dg.x) = 1U; (__cuda_local_var_43179_11_non_const_Dg.y) = 1U; (__cuda_local_var_43179_11_non_const_Dg.z) = 1U;
# 212 "pipeline.cu"
}


if (0 != ((int)(cudaMalloc(((void **)(&__cuda_local_var_43174_16_non_const_d_ts)), 8192UL))))
{
printf(((const char *)"cudaMalloc failed %s:%d\n"), ((const char *)("pipeline.cu")), 217);
return;
}
if (0 != ((int)(cudaMalloc(((void **)(&__cuda_local_var_43175_16_non_const_d_out)), 4UL))))
{
printf(((const char *)"cudaMalloc failed %s:%d\n"), ((const char *)("pipeline.cu")), 222);
return;
}

cudaGetLastError();
fprintf(stderr, ((const char *)"Running pipeline tests...\n\n"));



do {  enum cudaError __cuda_local_var_43198_108_non_const_error;
# 231 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_ADD_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_ADD_UINT_DEP128"))); if (((int)(__cuda_local_var_43198_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43198_108_non_const_error))); goto __T20; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T20:;
do {  enum cudaError __cuda_local_var_43199_111_non_const_error;
# 232 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z20K_RSQRT_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_RSQRT_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43199_111_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43199_111_non_const_error))); goto __T21; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T21:;
do {  enum cudaError __cuda_local_var_43200_110_non_const_error;
# 233 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_ADD_DOUBLE_DEP128PjS_ddi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_ADD_DOUBLE_DEP128"))); if (((int)(__cuda_local_var_43200_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43200_110_non_const_error))); goto __T22; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T22:;
printf(((const char *)"\n"));

do {  enum cudaError __cuda_local_var_43203_163_non_const_error;
# 236 "pipeline.cu"
 unsigned __cuda_local_var_43203_381_non_const_min_t;
# 236 "pipeline.cu"
 unsigned __cuda_local_var_43203_401_non_const_max_t;
# 236 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_ADD_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_ADD_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43203_163_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43203_163_non_const_error))); goto __T23; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43203_381_non_const_min_t = 4294967295U; __cuda_local_var_43203_401_non_const_max_t = 0U; {  int i;
# 236 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T24;
 unsigned __T25;
# 236 "pipeline.cu"
__cuda_local_var_43203_381_non_const_min_t = ((__T24 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43203_381_non_const_min_t, __T24))); __cuda_local_var_43203_401_non_const_max_t = ((__T25 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43203_401_non_const_max_t, __T25))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43203_401_non_const_max_t - __cuda_local_var_43203_381_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43203_401_non_const_max_t - __cuda_local_var_43203_381_non_const_min_t)))); } while (0); __T23:;
do {  enum cudaError __cuda_local_var_43204_169_non_const_error;
# 237 "pipeline.cu"
 unsigned __cuda_local_var_43204_387_non_const_min_t;
# 237 "pipeline.cu"
 unsigned __cuda_local_var_43204_407_non_const_max_t;
# 237 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_RSQRT_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z20K_RSQRT_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43204_169_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43204_169_non_const_error))); goto __T26; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43204_387_non_const_min_t = 4294967295U; __cuda_local_var_43204_407_non_const_max_t = 0U; {  int i;
# 237 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T27;
 unsigned __T28;
# 237 "pipeline.cu"
__cuda_local_var_43204_387_non_const_min_t = ((__T27 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43204_387_non_const_min_t, __T27))); __cuda_local_var_43204_407_non_const_max_t = ((__T28 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43204_407_non_const_max_t, __T28))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43204_407_non_const_max_t - __cuda_local_var_43204_387_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43204_407_non_const_max_t - __cuda_local_var_43204_387_non_const_min_t)))); } while (0); __T26:;
do {  enum cudaError __cuda_local_var_43205_167_non_const_error;
# 238 "pipeline.cu"
 unsigned __cuda_local_var_43205_385_non_const_min_t;
# 238 "pipeline.cu"
 unsigned __cuda_local_var_43205_405_non_const_max_t;
# 238 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_ADD_DOUBLE_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_ADD_DOUBLE_DEP128PjS_ddi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43205_167_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43205_167_non_const_error))); goto __T29; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43205_385_non_const_min_t = 4294967295U; __cuda_local_var_43205_405_non_const_max_t = 0U; {  int i;
# 238 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T210;
 unsigned __T211;
# 238 "pipeline.cu"
__cuda_local_var_43205_385_non_const_min_t = ((__T210 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43205_385_non_const_min_t, __T210))); __cuda_local_var_43205_405_non_const_max_t = ((__T211 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43205_405_non_const_max_t, __T211))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43205_405_non_const_max_t - __cuda_local_var_43205_385_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43205_405_non_const_max_t - __cuda_local_var_43205_385_non_const_min_t)))); } while (0); __T29:;
printf(((const char *)"\n"));


do {  enum cudaError __cuda_local_var_43209_108_non_const_error;
# 242 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_ADD_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_ADD_UINT_DEP128"))); if (((int)(__cuda_local_var_43209_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43209_108_non_const_error))); goto __T212; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T212:;
do {  enum cudaError __cuda_local_var_43210_108_non_const_error;
# 243 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_SUB_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SUB_UINT_DEP128"))); if (((int)(__cuda_local_var_43210_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43210_108_non_const_error))); goto __T213; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T213:;
do {  enum cudaError __cuda_local_var_43211_108_non_const_error;
# 244 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_MAD_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MAD_UINT_DEP128"))); if (((int)(__cuda_local_var_43211_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43211_108_non_const_error))); goto __T214; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T214:;
do {  enum cudaError __cuda_local_var_43212_108_non_const_error;
# 245 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_MUL_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MUL_UINT_DEP128"))); if (((int)(__cuda_local_var_43212_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43212_108_non_const_error))); goto __T215; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T215:;
do {  enum cudaError __cuda_local_var_43213_108_non_const_error;
# 246 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_DIV_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_DIV_UINT_DEP128"))); if (((int)(__cuda_local_var_43213_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43213_108_non_const_error))); goto __T216; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T216:;
do {  enum cudaError __cuda_local_var_43214_108_non_const_error;
# 247 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_REM_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_REM_UINT_DEP128"))); if (((int)(__cuda_local_var_43214_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43214_108_non_const_error))); goto __T217; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T217:;
do {  enum cudaError __cuda_local_var_43215_108_non_const_error;
# 248 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_MIN_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MIN_UINT_DEP128"))); if (((int)(__cuda_local_var_43215_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43215_108_non_const_error))); goto __T218; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T218:;
do {  enum cudaError __cuda_local_var_43216_108_non_const_error;
# 249 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_MAX_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MAX_UINT_DEP128"))); if (((int)(__cuda_local_var_43216_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43216_108_non_const_error))); goto __T219; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T219:;

do {  enum cudaError __cuda_local_var_43218_163_non_const_error;
# 251 "pipeline.cu"
 unsigned __cuda_local_var_43218_381_non_const_min_t;
# 251 "pipeline.cu"
 unsigned __cuda_local_var_43218_401_non_const_max_t;
# 251 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_ADD_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_ADD_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43218_163_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43218_163_non_const_error))); goto __T220; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43218_381_non_const_min_t = 4294967295U; __cuda_local_var_43218_401_non_const_max_t = 0U; {  int i;
# 251 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T221;
 unsigned __T222;
# 251 "pipeline.cu"
__cuda_local_var_43218_381_non_const_min_t = ((__T221 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43218_381_non_const_min_t, __T221))); __cuda_local_var_43218_401_non_const_max_t = ((__T222 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43218_401_non_const_max_t, __T222))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43218_401_non_const_max_t - __cuda_local_var_43218_381_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43218_401_non_const_max_t - __cuda_local_var_43218_381_non_const_min_t)))); } while (0); __T220:;
do {  enum cudaError __cuda_local_var_43219_163_non_const_error;
# 252 "pipeline.cu"
 unsigned __cuda_local_var_43219_381_non_const_min_t;
# 252 "pipeline.cu"
 unsigned __cuda_local_var_43219_401_non_const_max_t;
# 252 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_SUB_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_SUB_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43219_163_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43219_163_non_const_error))); goto __T223; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43219_381_non_const_min_t = 4294967295U; __cuda_local_var_43219_401_non_const_max_t = 0U; {  int i;
# 252 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T224;
 unsigned __T225;
# 252 "pipeline.cu"
__cuda_local_var_43219_381_non_const_min_t = ((__T224 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43219_381_non_const_min_t, __T224))); __cuda_local_var_43219_401_non_const_max_t = ((__T225 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43219_401_non_const_max_t, __T225))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43219_401_non_const_max_t - __cuda_local_var_43219_381_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43219_401_non_const_max_t - __cuda_local_var_43219_381_non_const_min_t)))); } while (0); __T223:;
do {  enum cudaError __cuda_local_var_43220_163_non_const_error;
# 253 "pipeline.cu"
 unsigned __cuda_local_var_43220_381_non_const_min_t;
# 253 "pipeline.cu"
 unsigned __cuda_local_var_43220_401_non_const_max_t;
# 253 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MAD_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_MAD_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43220_163_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43220_163_non_const_error))); goto __T226; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43220_381_non_const_min_t = 4294967295U; __cuda_local_var_43220_401_non_const_max_t = 0U; {  int i;
# 253 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T227;
 unsigned __T228;
# 253 "pipeline.cu"
__cuda_local_var_43220_381_non_const_min_t = ((__T227 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43220_381_non_const_min_t, __T227))); __cuda_local_var_43220_401_non_const_max_t = ((__T228 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43220_401_non_const_max_t, __T228))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43220_401_non_const_max_t - __cuda_local_var_43220_381_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43220_401_non_const_max_t - __cuda_local_var_43220_381_non_const_min_t)))); } while (0); __T226:;
do {  enum cudaError __cuda_local_var_43221_163_non_const_error;
# 254 "pipeline.cu"
 unsigned __cuda_local_var_43221_381_non_const_min_t;
# 254 "pipeline.cu"
 unsigned __cuda_local_var_43221_401_non_const_max_t;
# 254 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MUL_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_MUL_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43221_163_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43221_163_non_const_error))); goto __T229; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43221_381_non_const_min_t = 4294967295U; __cuda_local_var_43221_401_non_const_max_t = 0U; {  int i;
# 254 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T230;
 unsigned __T231;
# 254 "pipeline.cu"
__cuda_local_var_43221_381_non_const_min_t = ((__T230 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43221_381_non_const_min_t, __T230))); __cuda_local_var_43221_401_non_const_max_t = ((__T231 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43221_401_non_const_max_t, __T231))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43221_401_non_const_max_t - __cuda_local_var_43221_381_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43221_401_non_const_max_t - __cuda_local_var_43221_381_non_const_min_t)))); } while (0); __T229:;
do {  enum cudaError __cuda_local_var_43222_163_non_const_error;
# 255 "pipeline.cu"
 unsigned __cuda_local_var_43222_381_non_const_min_t;
# 255 "pipeline.cu"
 unsigned __cuda_local_var_43222_401_non_const_max_t;
# 255 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_DIV_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_DIV_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43222_163_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43222_163_non_const_error))); goto __T232; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43222_381_non_const_min_t = 4294967295U; __cuda_local_var_43222_401_non_const_max_t = 0U; {  int i;
# 255 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T233;
 unsigned __T234;
# 255 "pipeline.cu"
__cuda_local_var_43222_381_non_const_min_t = ((__T233 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43222_381_non_const_min_t, __T233))); __cuda_local_var_43222_401_non_const_max_t = ((__T234 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43222_401_non_const_max_t, __T234))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43222_401_non_const_max_t - __cuda_local_var_43222_381_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43222_401_non_const_max_t - __cuda_local_var_43222_381_non_const_min_t)))); } while (0); __T232:;
do {  enum cudaError __cuda_local_var_43223_163_non_const_error;
# 256 "pipeline.cu"
 unsigned __cuda_local_var_43223_381_non_const_min_t;
# 256 "pipeline.cu"
 unsigned __cuda_local_var_43223_401_non_const_max_t;
# 256 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_REM_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_REM_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43223_163_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43223_163_non_const_error))); goto __T235; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43223_381_non_const_min_t = 4294967295U; __cuda_local_var_43223_401_non_const_max_t = 0U; {  int i;
# 256 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T236;
 unsigned __T237;
# 256 "pipeline.cu"
__cuda_local_var_43223_381_non_const_min_t = ((__T236 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43223_381_non_const_min_t, __T236))); __cuda_local_var_43223_401_non_const_max_t = ((__T237 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43223_401_non_const_max_t, __T237))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43223_401_non_const_max_t - __cuda_local_var_43223_381_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43223_401_non_const_max_t - __cuda_local_var_43223_381_non_const_min_t)))); } while (0); __T235:;
do {  enum cudaError __cuda_local_var_43224_163_non_const_error;
# 257 "pipeline.cu"
 unsigned __cuda_local_var_43224_381_non_const_min_t;
# 257 "pipeline.cu"
 unsigned __cuda_local_var_43224_401_non_const_max_t;
# 257 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MIN_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_MIN_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43224_163_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43224_163_non_const_error))); goto __T238; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43224_381_non_const_min_t = 4294967295U; __cuda_local_var_43224_401_non_const_max_t = 0U; {  int i;
# 257 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T239;
 unsigned __T240;
# 257 "pipeline.cu"
__cuda_local_var_43224_381_non_const_min_t = ((__T239 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43224_381_non_const_min_t, __T239))); __cuda_local_var_43224_401_non_const_max_t = ((__T240 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43224_401_non_const_max_t, __T240))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43224_401_non_const_max_t - __cuda_local_var_43224_381_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43224_401_non_const_max_t - __cuda_local_var_43224_381_non_const_min_t)))); } while (0); __T238:;
do {  enum cudaError __cuda_local_var_43225_163_non_const_error;
# 258 "pipeline.cu"
 unsigned __cuda_local_var_43225_381_non_const_min_t;
# 258 "pipeline.cu"
 unsigned __cuda_local_var_43225_401_non_const_max_t;
# 258 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MAX_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_MAX_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43225_163_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43225_163_non_const_error))); goto __T241; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43225_381_non_const_min_t = 4294967295U; __cuda_local_var_43225_401_non_const_max_t = 0U; {  int i;
# 258 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T242;
 unsigned __T243;
# 258 "pipeline.cu"
__cuda_local_var_43225_381_non_const_min_t = ((__T242 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43225_381_non_const_min_t, __T242))); __cuda_local_var_43225_401_non_const_max_t = ((__T243 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43225_401_non_const_max_t, __T243))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43225_401_non_const_max_t - __cuda_local_var_43225_381_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43225_401_non_const_max_t - __cuda_local_var_43225_381_non_const_min_t)))); } while (0); __T241:;
printf(((const char *)"\n"));


do {  enum cudaError __cuda_local_var_43229_107_non_const_error;
# 262 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_ADD_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_ADD_INT_DEP128"))); if (((int)(__cuda_local_var_43229_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43229_107_non_const_error))); goto __T244; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T244:;
do {  enum cudaError __cuda_local_var_43230_107_non_const_error;
# 263 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_SUB_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SUB_INT_DEP128"))); if (((int)(__cuda_local_var_43230_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43230_107_non_const_error))); goto __T245; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T245:;
do {  enum cudaError __cuda_local_var_43231_107_non_const_error;
# 264 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_MAD_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MAD_INT_DEP128"))); if (((int)(__cuda_local_var_43231_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43231_107_non_const_error))); goto __T246; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T246:;
do {  enum cudaError __cuda_local_var_43232_107_non_const_error;
# 265 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_MUL_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MUL_INT_DEP128"))); if (((int)(__cuda_local_var_43232_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43232_107_non_const_error))); goto __T247; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T247:;
do {  enum cudaError __cuda_local_var_43233_107_non_const_error;
# 266 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_DIV_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_DIV_INT_DEP128"))); if (((int)(__cuda_local_var_43233_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43233_107_non_const_error))); goto __T248; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T248:;
do {  enum cudaError __cuda_local_var_43234_107_non_const_error;
# 267 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_REM_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_REM_INT_DEP128"))); if (((int)(__cuda_local_var_43234_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43234_107_non_const_error))); goto __T249; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T249:;
do {  enum cudaError __cuda_local_var_43235_107_non_const_error;
# 268 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_MIN_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MIN_INT_DEP128"))); if (((int)(__cuda_local_var_43235_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43235_107_non_const_error))); goto __T250; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T250:;
do {  enum cudaError __cuda_local_var_43236_107_non_const_error;
# 269 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_MAX_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MAX_INT_DEP128"))); if (((int)(__cuda_local_var_43236_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43236_107_non_const_error))); goto __T251; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T251:;
do {  enum cudaError __cuda_local_var_43237_107_non_const_error;
# 270 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_ABS_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_ABS_INT_DEP128"))); if (((int)(__cuda_local_var_43237_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43237_107_non_const_error))); goto __T252; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T252:;

do {  enum cudaError __cuda_local_var_43239_161_non_const_error;
# 272 "pipeline.cu"
 unsigned __cuda_local_var_43239_379_non_const_min_t;
# 272 "pipeline.cu"
 unsigned __cuda_local_var_43239_399_non_const_max_t;
# 272 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_ADD_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_ADD_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43239_161_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43239_161_non_const_error))); goto __T253; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43239_379_non_const_min_t = 4294967295U; __cuda_local_var_43239_399_non_const_max_t = 0U; {  int i;
# 272 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T254;
 unsigned __T255;
# 272 "pipeline.cu"
__cuda_local_var_43239_379_non_const_min_t = ((__T254 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43239_379_non_const_min_t, __T254))); __cuda_local_var_43239_399_non_const_max_t = ((__T255 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43239_399_non_const_max_t, __T255))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43239_399_non_const_max_t - __cuda_local_var_43239_379_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43239_399_non_const_max_t - __cuda_local_var_43239_379_non_const_min_t)))); } while (0); __T253:;
do {  enum cudaError __cuda_local_var_43240_161_non_const_error;
# 273 "pipeline.cu"
 unsigned __cuda_local_var_43240_379_non_const_min_t;
# 273 "pipeline.cu"
 unsigned __cuda_local_var_43240_399_non_const_max_t;
# 273 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_SUB_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_SUB_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43240_161_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43240_161_non_const_error))); goto __T256; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43240_379_non_const_min_t = 4294967295U; __cuda_local_var_43240_399_non_const_max_t = 0U; {  int i;
# 273 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T257;
 unsigned __T258;
# 273 "pipeline.cu"
__cuda_local_var_43240_379_non_const_min_t = ((__T257 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43240_379_non_const_min_t, __T257))); __cuda_local_var_43240_399_non_const_max_t = ((__T258 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43240_399_non_const_max_t, __T258))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43240_399_non_const_max_t - __cuda_local_var_43240_379_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43240_399_non_const_max_t - __cuda_local_var_43240_379_non_const_min_t)))); } while (0); __T256:;
do {  enum cudaError __cuda_local_var_43241_161_non_const_error;
# 274 "pipeline.cu"
 unsigned __cuda_local_var_43241_379_non_const_min_t;
# 274 "pipeline.cu"
 unsigned __cuda_local_var_43241_399_non_const_max_t;
# 274 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MAD_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_MAD_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43241_161_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43241_161_non_const_error))); goto __T259; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43241_379_non_const_min_t = 4294967295U; __cuda_local_var_43241_399_non_const_max_t = 0U; {  int i;
# 274 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T260;
 unsigned __T261;
# 274 "pipeline.cu"
__cuda_local_var_43241_379_non_const_min_t = ((__T260 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43241_379_non_const_min_t, __T260))); __cuda_local_var_43241_399_non_const_max_t = ((__T261 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43241_399_non_const_max_t, __T261))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43241_399_non_const_max_t - __cuda_local_var_43241_379_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43241_399_non_const_max_t - __cuda_local_var_43241_379_non_const_min_t)))); } while (0); __T259:;
do {  enum cudaError __cuda_local_var_43242_161_non_const_error;
# 275 "pipeline.cu"
 unsigned __cuda_local_var_43242_379_non_const_min_t;
# 275 "pipeline.cu"
 unsigned __cuda_local_var_43242_399_non_const_max_t;
# 275 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MUL_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_MUL_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43242_161_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43242_161_non_const_error))); goto __T262; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43242_379_non_const_min_t = 4294967295U; __cuda_local_var_43242_399_non_const_max_t = 0U; {  int i;
# 275 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T263;
 unsigned __T264;
# 275 "pipeline.cu"
__cuda_local_var_43242_379_non_const_min_t = ((__T263 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43242_379_non_const_min_t, __T263))); __cuda_local_var_43242_399_non_const_max_t = ((__T264 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43242_399_non_const_max_t, __T264))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43242_399_non_const_max_t - __cuda_local_var_43242_379_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43242_399_non_const_max_t - __cuda_local_var_43242_379_non_const_min_t)))); } while (0); __T262:;
do {  enum cudaError __cuda_local_var_43243_161_non_const_error;
# 276 "pipeline.cu"
 unsigned __cuda_local_var_43243_379_non_const_min_t;
# 276 "pipeline.cu"
 unsigned __cuda_local_var_43243_399_non_const_max_t;
# 276 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_DIV_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_DIV_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43243_161_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43243_161_non_const_error))); goto __T265; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43243_379_non_const_min_t = 4294967295U; __cuda_local_var_43243_399_non_const_max_t = 0U; {  int i;
# 276 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T266;
 unsigned __T267;
# 276 "pipeline.cu"
__cuda_local_var_43243_379_non_const_min_t = ((__T266 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43243_379_non_const_min_t, __T266))); __cuda_local_var_43243_399_non_const_max_t = ((__T267 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43243_399_non_const_max_t, __T267))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43243_399_non_const_max_t - __cuda_local_var_43243_379_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43243_399_non_const_max_t - __cuda_local_var_43243_379_non_const_min_t)))); } while (0); __T265:;
do {  enum cudaError __cuda_local_var_43244_161_non_const_error;
# 277 "pipeline.cu"
 unsigned __cuda_local_var_43244_379_non_const_min_t;
# 277 "pipeline.cu"
 unsigned __cuda_local_var_43244_399_non_const_max_t;
# 277 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_REM_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_REM_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43244_161_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43244_161_non_const_error))); goto __T268; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43244_379_non_const_min_t = 4294967295U; __cuda_local_var_43244_399_non_const_max_t = 0U; {  int i;
# 277 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T269;
 unsigned __T270;
# 277 "pipeline.cu"
__cuda_local_var_43244_379_non_const_min_t = ((__T269 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43244_379_non_const_min_t, __T269))); __cuda_local_var_43244_399_non_const_max_t = ((__T270 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43244_399_non_const_max_t, __T270))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43244_399_non_const_max_t - __cuda_local_var_43244_379_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43244_399_non_const_max_t - __cuda_local_var_43244_379_non_const_min_t)))); } while (0); __T268:;
do {  enum cudaError __cuda_local_var_43245_161_non_const_error;
# 278 "pipeline.cu"
 unsigned __cuda_local_var_43245_379_non_const_min_t;
# 278 "pipeline.cu"
 unsigned __cuda_local_var_43245_399_non_const_max_t;
# 278 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MIN_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_MIN_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43245_161_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43245_161_non_const_error))); goto __T271; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43245_379_non_const_min_t = 4294967295U; __cuda_local_var_43245_399_non_const_max_t = 0U; {  int i;
# 278 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T272;
 unsigned __T273;
# 278 "pipeline.cu"
__cuda_local_var_43245_379_non_const_min_t = ((__T272 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43245_379_non_const_min_t, __T272))); __cuda_local_var_43245_399_non_const_max_t = ((__T273 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43245_399_non_const_max_t, __T273))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43245_399_non_const_max_t - __cuda_local_var_43245_379_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43245_399_non_const_max_t - __cuda_local_var_43245_379_non_const_min_t)))); } while (0); __T271:;
do {  enum cudaError __cuda_local_var_43246_161_non_const_error;
# 279 "pipeline.cu"
 unsigned __cuda_local_var_43246_379_non_const_min_t;
# 279 "pipeline.cu"
 unsigned __cuda_local_var_43246_399_non_const_max_t;
# 279 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MAX_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_MAX_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43246_161_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43246_161_non_const_error))); goto __T274; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43246_379_non_const_min_t = 4294967295U; __cuda_local_var_43246_399_non_const_max_t = 0U; {  int i;
# 279 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T275;
 unsigned __T276;
# 279 "pipeline.cu"
__cuda_local_var_43246_379_non_const_min_t = ((__T275 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43246_379_non_const_min_t, __T275))); __cuda_local_var_43246_399_non_const_max_t = ((__T276 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43246_399_non_const_max_t, __T276))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43246_399_non_const_max_t - __cuda_local_var_43246_379_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43246_399_non_const_max_t - __cuda_local_var_43246_379_non_const_min_t)))); } while (0); __T274:;
do {  enum cudaError __cuda_local_var_43247_161_non_const_error;
# 280 "pipeline.cu"
 unsigned __cuda_local_var_43247_379_non_const_min_t;
# 280 "pipeline.cu"
 unsigned __cuda_local_var_43247_399_non_const_max_t;
# 280 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_ABS_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_ABS_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43247_161_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43247_161_non_const_error))); goto __T277; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43247_379_non_const_min_t = 4294967295U; __cuda_local_var_43247_399_non_const_max_t = 0U; {  int i;
# 280 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T278;
 unsigned __T279;
# 280 "pipeline.cu"
__cuda_local_var_43247_379_non_const_min_t = ((__T278 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43247_379_non_const_min_t, __T278))); __cuda_local_var_43247_399_non_const_max_t = ((__T279 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43247_399_non_const_max_t, __T279))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43247_399_non_const_max_t - __cuda_local_var_43247_379_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43247_399_non_const_max_t - __cuda_local_var_43247_379_non_const_min_t)))); } while (0); __T277:;
printf(((const char *)"\n"));


do {  enum cudaError __cuda_local_var_43251_109_non_const_error;
# 284 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_ADD_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_ADD_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43251_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43251_109_non_const_error))); goto __T280; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T280:;
do {  enum cudaError __cuda_local_var_43252_109_non_const_error;
# 285 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_SUB_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SUB_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43252_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43252_109_non_const_error))); goto __T281; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T281:;
do {  enum cudaError __cuda_local_var_43253_109_non_const_error;
# 286 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_MAD_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MAD_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43253_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43253_109_non_const_error))); goto __T282; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T282:;
do {  enum cudaError __cuda_local_var_43254_109_non_const_error;
# 287 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_MUL_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MUL_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43254_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43254_109_non_const_error))); goto __T283; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T283:;
do {  enum cudaError __cuda_local_var_43255_109_non_const_error;
# 288 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_DIV_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_DIV_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43255_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43255_109_non_const_error))); goto __T284; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T284:;
do {  enum cudaError __cuda_local_var_43256_109_non_const_error;
# 289 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_MIN_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MIN_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43256_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43256_109_non_const_error))); goto __T285; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T285:;
do {  enum cudaError __cuda_local_var_43257_109_non_const_error;
# 290 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_MAX_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MAX_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43257_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43257_109_non_const_error))); goto __T286; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T286:;

do {  enum cudaError __cuda_local_var_43259_165_non_const_error;
# 292 "pipeline.cu"
 unsigned __cuda_local_var_43259_383_non_const_min_t;
# 292 "pipeline.cu"
 unsigned __cuda_local_var_43259_403_non_const_max_t;
# 292 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_ADD_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_ADD_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43259_165_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43259_165_non_const_error))); goto __T287; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43259_383_non_const_min_t = 4294967295U; __cuda_local_var_43259_403_non_const_max_t = 0U; {  int i;
# 292 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T288;
 unsigned __T289;
# 292 "pipeline.cu"
__cuda_local_var_43259_383_non_const_min_t = ((__T288 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43259_383_non_const_min_t, __T288))); __cuda_local_var_43259_403_non_const_max_t = ((__T289 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43259_403_non_const_max_t, __T289))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43259_403_non_const_max_t - __cuda_local_var_43259_383_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43259_403_non_const_max_t - __cuda_local_var_43259_383_non_const_min_t)))); } while (0); __T287:;
do {  enum cudaError __cuda_local_var_43260_165_non_const_error;
# 293 "pipeline.cu"
 unsigned __cuda_local_var_43260_383_non_const_min_t;
# 293 "pipeline.cu"
 unsigned __cuda_local_var_43260_403_non_const_max_t;
# 293 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_SUB_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_SUB_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43260_165_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43260_165_non_const_error))); goto __T290; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43260_383_non_const_min_t = 4294967295U; __cuda_local_var_43260_403_non_const_max_t = 0U; {  int i;
# 293 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T291;
 unsigned __T292;
# 293 "pipeline.cu"
__cuda_local_var_43260_383_non_const_min_t = ((__T291 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43260_383_non_const_min_t, __T291))); __cuda_local_var_43260_403_non_const_max_t = ((__T292 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43260_403_non_const_max_t, __T292))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43260_403_non_const_max_t - __cuda_local_var_43260_383_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43260_403_non_const_max_t - __cuda_local_var_43260_383_non_const_min_t)))); } while (0); __T290:;
do {  enum cudaError __cuda_local_var_43261_165_non_const_error;
# 294 "pipeline.cu"
 unsigned __cuda_local_var_43261_383_non_const_min_t;
# 294 "pipeline.cu"
 unsigned __cuda_local_var_43261_403_non_const_max_t;
# 294 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MAD_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_MAD_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43261_165_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43261_165_non_const_error))); goto __T293; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43261_383_non_const_min_t = 4294967295U; __cuda_local_var_43261_403_non_const_max_t = 0U; {  int i;
# 294 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T294;
 unsigned __T295;
# 294 "pipeline.cu"
__cuda_local_var_43261_383_non_const_min_t = ((__T294 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43261_383_non_const_min_t, __T294))); __cuda_local_var_43261_403_non_const_max_t = ((__T295 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43261_403_non_const_max_t, __T295))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43261_403_non_const_max_t - __cuda_local_var_43261_383_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43261_403_non_const_max_t - __cuda_local_var_43261_383_non_const_min_t)))); } while (0); __T293:;
do {  enum cudaError __cuda_local_var_43262_165_non_const_error;
# 295 "pipeline.cu"
 unsigned __cuda_local_var_43262_383_non_const_min_t;
# 295 "pipeline.cu"
 unsigned __cuda_local_var_43262_403_non_const_max_t;
# 295 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MUL_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_MUL_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43262_165_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43262_165_non_const_error))); goto __T296; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43262_383_non_const_min_t = 4294967295U; __cuda_local_var_43262_403_non_const_max_t = 0U; {  int i;
# 295 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T297;
 unsigned __T298;
# 295 "pipeline.cu"
__cuda_local_var_43262_383_non_const_min_t = ((__T297 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43262_383_non_const_min_t, __T297))); __cuda_local_var_43262_403_non_const_max_t = ((__T298 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43262_403_non_const_max_t, __T298))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43262_403_non_const_max_t - __cuda_local_var_43262_383_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43262_403_non_const_max_t - __cuda_local_var_43262_383_non_const_min_t)))); } while (0); __T296:;
do {  enum cudaError __cuda_local_var_43263_165_non_const_error;
# 296 "pipeline.cu"
 unsigned __cuda_local_var_43263_383_non_const_min_t;
# 296 "pipeline.cu"
 unsigned __cuda_local_var_43263_403_non_const_max_t;
# 296 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_DIV_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_DIV_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43263_165_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43263_165_non_const_error))); goto __T299; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43263_383_non_const_min_t = 4294967295U; __cuda_local_var_43263_403_non_const_max_t = 0U; {  int i;
# 296 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2100;
 unsigned __T2101;
# 296 "pipeline.cu"
__cuda_local_var_43263_383_non_const_min_t = ((__T2100 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43263_383_non_const_min_t, __T2100))); __cuda_local_var_43263_403_non_const_max_t = ((__T2101 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43263_403_non_const_max_t, __T2101))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43263_403_non_const_max_t - __cuda_local_var_43263_383_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43263_403_non_const_max_t - __cuda_local_var_43263_383_non_const_min_t)))); } while (0); __T299:;
do {  enum cudaError __cuda_local_var_43264_165_non_const_error;
# 297 "pipeline.cu"
 unsigned __cuda_local_var_43264_383_non_const_min_t;
# 297 "pipeline.cu"
 unsigned __cuda_local_var_43264_403_non_const_max_t;
# 297 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MIN_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_MIN_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43264_165_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43264_165_non_const_error))); goto __T2102; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43264_383_non_const_min_t = 4294967295U; __cuda_local_var_43264_403_non_const_max_t = 0U; {  int i;
# 297 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2103;
 unsigned __T2104;
# 297 "pipeline.cu"
__cuda_local_var_43264_383_non_const_min_t = ((__T2103 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43264_383_non_const_min_t, __T2103))); __cuda_local_var_43264_403_non_const_max_t = ((__T2104 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43264_403_non_const_max_t, __T2104))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43264_403_non_const_max_t - __cuda_local_var_43264_383_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43264_403_non_const_max_t - __cuda_local_var_43264_383_non_const_min_t)))); } while (0); __T2102:;
do {  enum cudaError __cuda_local_var_43265_165_non_const_error;
# 298 "pipeline.cu"
 unsigned __cuda_local_var_43265_383_non_const_min_t;
# 298 "pipeline.cu"
 unsigned __cuda_local_var_43265_403_non_const_max_t;
# 298 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MAX_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_MAX_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43265_165_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43265_165_non_const_error))); goto __T2105; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43265_383_non_const_min_t = 4294967295U; __cuda_local_var_43265_403_non_const_max_t = 0U; {  int i;
# 298 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2106;
 unsigned __T2107;
# 298 "pipeline.cu"
__cuda_local_var_43265_383_non_const_min_t = ((__T2106 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43265_383_non_const_min_t, __T2106))); __cuda_local_var_43265_403_non_const_max_t = ((__T2107 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43265_403_non_const_max_t, __T2107))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43265_403_non_const_max_t - __cuda_local_var_43265_383_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43265_403_non_const_max_t - __cuda_local_var_43265_383_non_const_min_t)))); } while (0); __T2105:;
printf(((const char *)"\n"));



do {  enum cudaError __cuda_local_var_43270_110_non_const_error;
# 303 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_ADD_DOUBLE_DEP128PjS_ddi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_ADD_DOUBLE_DEP128"))); if (((int)(__cuda_local_var_43270_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43270_110_non_const_error))); goto __T2108; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2108:;
do {  enum cudaError __cuda_local_var_43271_110_non_const_error;
# 304 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_SUB_DOUBLE_DEP128PjS_ddi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SUB_DOUBLE_DEP128"))); if (((int)(__cuda_local_var_43271_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43271_110_non_const_error))); goto __T2109; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2109:;
do {  enum cudaError __cuda_local_var_43272_110_non_const_error;
# 305 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_MAD_DOUBLE_DEP128PjS_ddi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MAD_DOUBLE_DEP128"))); if (((int)(__cuda_local_var_43272_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43272_110_non_const_error))); goto __T2110; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2110:;
do {  enum cudaError __cuda_local_var_43273_110_non_const_error;
# 306 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_MUL_DOUBLE_DEP128PjS_ddi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MUL_DOUBLE_DEP128"))); if (((int)(__cuda_local_var_43273_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43273_110_non_const_error))); goto __T2111; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2111:;
do {  enum cudaError __cuda_local_var_43274_110_non_const_error;
# 307 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_DIV_DOUBLE_DEP128PjS_ddi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_DIV_DOUBLE_DEP128"))); if (((int)(__cuda_local_var_43274_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43274_110_non_const_error))); goto __T2112; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2112:;
do {  enum cudaError __cuda_local_var_43275_110_non_const_error;
# 308 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_MIN_DOUBLE_DEP128PjS_ddi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MIN_DOUBLE_DEP128"))); if (((int)(__cuda_local_var_43275_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43275_110_non_const_error))); goto __T2113; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2113:;
do {  enum cudaError __cuda_local_var_43276_110_non_const_error;
# 309 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_MAX_DOUBLE_DEP128PjS_ddi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MAX_DOUBLE_DEP128"))); if (((int)(__cuda_local_var_43276_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43276_110_non_const_error))); goto __T2114; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2114:;

do {  enum cudaError __cuda_local_var_43278_167_non_const_error;
# 311 "pipeline.cu"
 unsigned __cuda_local_var_43278_385_non_const_min_t;
# 311 "pipeline.cu"
 unsigned __cuda_local_var_43278_405_non_const_max_t;
# 311 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_ADD_DOUBLE_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_ADD_DOUBLE_DEP128PjS_ddi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43278_167_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43278_167_non_const_error))); goto __T2115; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43278_385_non_const_min_t = 4294967295U; __cuda_local_var_43278_405_non_const_max_t = 0U; {  int i;
# 311 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2116;
 unsigned __T2117;
# 311 "pipeline.cu"
__cuda_local_var_43278_385_non_const_min_t = ((__T2116 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43278_385_non_const_min_t, __T2116))); __cuda_local_var_43278_405_non_const_max_t = ((__T2117 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43278_405_non_const_max_t, __T2117))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43278_405_non_const_max_t - __cuda_local_var_43278_385_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43278_405_non_const_max_t - __cuda_local_var_43278_385_non_const_min_t)))); } while (0); __T2115:;
do {  enum cudaError __cuda_local_var_43279_167_non_const_error;
# 312 "pipeline.cu"
 unsigned __cuda_local_var_43279_385_non_const_min_t;
# 312 "pipeline.cu"
 unsigned __cuda_local_var_43279_405_non_const_max_t;
# 312 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_SUB_DOUBLE_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_SUB_DOUBLE_DEP128PjS_ddi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43279_167_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43279_167_non_const_error))); goto __T2118; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43279_385_non_const_min_t = 4294967295U; __cuda_local_var_43279_405_non_const_max_t = 0U; {  int i;
# 312 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2119;
 unsigned __T2120;
# 312 "pipeline.cu"
__cuda_local_var_43279_385_non_const_min_t = ((__T2119 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43279_385_non_const_min_t, __T2119))); __cuda_local_var_43279_405_non_const_max_t = ((__T2120 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43279_405_non_const_max_t, __T2120))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43279_405_non_const_max_t - __cuda_local_var_43279_385_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43279_405_non_const_max_t - __cuda_local_var_43279_385_non_const_min_t)))); } while (0); __T2118:;
do {  enum cudaError __cuda_local_var_43280_167_non_const_error;
# 313 "pipeline.cu"
 unsigned __cuda_local_var_43280_385_non_const_min_t;
# 313 "pipeline.cu"
 unsigned __cuda_local_var_43280_405_non_const_max_t;
# 313 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MAD_DOUBLE_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_MAD_DOUBLE_DEP128PjS_ddi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43280_167_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43280_167_non_const_error))); goto __T2121; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43280_385_non_const_min_t = 4294967295U; __cuda_local_var_43280_405_non_const_max_t = 0U; {  int i;
# 313 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2122;
 unsigned __T2123;
# 313 "pipeline.cu"
__cuda_local_var_43280_385_non_const_min_t = ((__T2122 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43280_385_non_const_min_t, __T2122))); __cuda_local_var_43280_405_non_const_max_t = ((__T2123 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43280_405_non_const_max_t, __T2123))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43280_405_non_const_max_t - __cuda_local_var_43280_385_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43280_405_non_const_max_t - __cuda_local_var_43280_385_non_const_min_t)))); } while (0); __T2121:;
do {  enum cudaError __cuda_local_var_43281_167_non_const_error;
# 314 "pipeline.cu"
 unsigned __cuda_local_var_43281_385_non_const_min_t;
# 314 "pipeline.cu"
 unsigned __cuda_local_var_43281_405_non_const_max_t;
# 314 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MUL_DOUBLE_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_MUL_DOUBLE_DEP128PjS_ddi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43281_167_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43281_167_non_const_error))); goto __T2124; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43281_385_non_const_min_t = 4294967295U; __cuda_local_var_43281_405_non_const_max_t = 0U; {  int i;
# 314 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2125;
 unsigned __T2126;
# 314 "pipeline.cu"
__cuda_local_var_43281_385_non_const_min_t = ((__T2125 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43281_385_non_const_min_t, __T2125))); __cuda_local_var_43281_405_non_const_max_t = ((__T2126 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43281_405_non_const_max_t, __T2126))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43281_405_non_const_max_t - __cuda_local_var_43281_385_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43281_405_non_const_max_t - __cuda_local_var_43281_385_non_const_min_t)))); } while (0); __T2124:;
do {  enum cudaError __cuda_local_var_43282_167_non_const_error;
# 315 "pipeline.cu"
 unsigned __cuda_local_var_43282_385_non_const_min_t;
# 315 "pipeline.cu"
 unsigned __cuda_local_var_43282_405_non_const_max_t;
# 315 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_DIV_DOUBLE_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_DIV_DOUBLE_DEP128PjS_ddi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43282_167_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43282_167_non_const_error))); goto __T2127; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43282_385_non_const_min_t = 4294967295U; __cuda_local_var_43282_405_non_const_max_t = 0U; {  int i;
# 315 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2128;
 unsigned __T2129;
# 315 "pipeline.cu"
__cuda_local_var_43282_385_non_const_min_t = ((__T2128 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43282_385_non_const_min_t, __T2128))); __cuda_local_var_43282_405_non_const_max_t = ((__T2129 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43282_405_non_const_max_t, __T2129))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43282_405_non_const_max_t - __cuda_local_var_43282_385_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43282_405_non_const_max_t - __cuda_local_var_43282_385_non_const_min_t)))); } while (0); __T2127:;
do {  enum cudaError __cuda_local_var_43283_167_non_const_error;
# 316 "pipeline.cu"
 unsigned __cuda_local_var_43283_385_non_const_min_t;
# 316 "pipeline.cu"
 unsigned __cuda_local_var_43283_405_non_const_max_t;
# 316 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MIN_DOUBLE_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_MIN_DOUBLE_DEP128PjS_ddi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43283_167_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43283_167_non_const_error))); goto __T2130; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43283_385_non_const_min_t = 4294967295U; __cuda_local_var_43283_405_non_const_max_t = 0U; {  int i;
# 316 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2131;
 unsigned __T2132;
# 316 "pipeline.cu"
__cuda_local_var_43283_385_non_const_min_t = ((__T2131 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43283_385_non_const_min_t, __T2131))); __cuda_local_var_43283_405_non_const_max_t = ((__T2132 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43283_405_non_const_max_t, __T2132))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43283_405_non_const_max_t - __cuda_local_var_43283_385_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43283_405_non_const_max_t - __cuda_local_var_43283_385_non_const_min_t)))); } while (0); __T2130:;
do {  enum cudaError __cuda_local_var_43284_167_non_const_error;
# 317 "pipeline.cu"
 unsigned __cuda_local_var_43284_385_non_const_min_t;
# 317 "pipeline.cu"
 unsigned __cuda_local_var_43284_405_non_const_max_t;
# 317 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MAX_DOUBLE_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_MAX_DOUBLE_DEP128PjS_ddi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43284_167_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43284_167_non_const_error))); goto __T2133; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43284_385_non_const_min_t = 4294967295U; __cuda_local_var_43284_405_non_const_max_t = 0U; {  int i;
# 317 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2134;
 unsigned __T2135;
# 317 "pipeline.cu"
__cuda_local_var_43284_385_non_const_min_t = ((__T2134 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43284_385_non_const_min_t, __T2134))); __cuda_local_var_43284_405_non_const_max_t = ((__T2135 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43284_405_non_const_max_t, __T2135))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43284_405_non_const_max_t - __cuda_local_var_43284_385_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43284_405_non_const_max_t - __cuda_local_var_43284_385_non_const_min_t)))); } while (0); __T2133:;
printf(((const char *)"\n"));


do {  enum cudaError __cuda_local_var_43288_108_non_const_error;
# 321 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_AND_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_AND_UINT_DEP128"))); if (((int)(__cuda_local_var_43288_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43288_108_non_const_error))); goto __T2136; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2136:;
do {  enum cudaError __cuda_local_var_43289_107_non_const_error;
# 322 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_OR_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_OR_UINT_DEP128"))); if (((int)(__cuda_local_var_43289_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43289_107_non_const_error))); goto __T2137; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2137:;
do {  enum cudaError __cuda_local_var_43290_108_non_const_error;
# 323 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_XOR_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_XOR_UINT_DEP128"))); if (((int)(__cuda_local_var_43290_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43290_108_non_const_error))); goto __T2138; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2138:;
do {  enum cudaError __cuda_local_var_43291_108_non_const_error;
# 324 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_SHL_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SHL_UINT_DEP128"))); if (((int)(__cuda_local_var_43291_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43291_108_non_const_error))); goto __T2139; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2139:;
do {  enum cudaError __cuda_local_var_43292_108_non_const_error;
# 325 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_SHR_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SHR_UINT_DEP128"))); if (((int)(__cuda_local_var_43292_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43292_108_non_const_error))); goto __T2140; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2140:;

do {  enum cudaError __cuda_local_var_43294_163_non_const_error;
# 327 "pipeline.cu"
 unsigned __cuda_local_var_43294_381_non_const_min_t;
# 327 "pipeline.cu"
 unsigned __cuda_local_var_43294_401_non_const_max_t;
# 327 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_AND_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_AND_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43294_163_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43294_163_non_const_error))); goto __T2141; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43294_381_non_const_min_t = 4294967295U; __cuda_local_var_43294_401_non_const_max_t = 0U; {  int i;
# 327 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2142;
 unsigned __T2143;
# 327 "pipeline.cu"
__cuda_local_var_43294_381_non_const_min_t = ((__T2142 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43294_381_non_const_min_t, __T2142))); __cuda_local_var_43294_401_non_const_max_t = ((__T2143 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43294_401_non_const_max_t, __T2143))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43294_401_non_const_max_t - __cuda_local_var_43294_381_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43294_401_non_const_max_t - __cuda_local_var_43294_381_non_const_min_t)))); } while (0); __T2141:;
do {  enum cudaError __cuda_local_var_43295_161_non_const_error;
# 328 "pipeline.cu"
 unsigned __cuda_local_var_43295_379_non_const_min_t;
# 328 "pipeline.cu"
 unsigned __cuda_local_var_43295_399_non_const_max_t;
# 328 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_OR_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_OR_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43295_161_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43295_161_non_const_error))); goto __T2144; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43295_379_non_const_min_t = 4294967295U; __cuda_local_var_43295_399_non_const_max_t = 0U; {  int i;
# 328 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2145;
 unsigned __T2146;
# 328 "pipeline.cu"
__cuda_local_var_43295_379_non_const_min_t = ((__T2145 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43295_379_non_const_min_t, __T2145))); __cuda_local_var_43295_399_non_const_max_t = ((__T2146 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43295_399_non_const_max_t, __T2146))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43295_399_non_const_max_t - __cuda_local_var_43295_379_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43295_399_non_const_max_t - __cuda_local_var_43295_379_non_const_min_t)))); } while (0); __T2144:;
do {  enum cudaError __cuda_local_var_43296_163_non_const_error;
# 329 "pipeline.cu"
 unsigned __cuda_local_var_43296_381_non_const_min_t;
# 329 "pipeline.cu"
 unsigned __cuda_local_var_43296_401_non_const_max_t;
# 329 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_XOR_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_XOR_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43296_163_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43296_163_non_const_error))); goto __T2147; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43296_381_non_const_min_t = 4294967295U; __cuda_local_var_43296_401_non_const_max_t = 0U; {  int i;
# 329 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2148;
 unsigned __T2149;
# 329 "pipeline.cu"
__cuda_local_var_43296_381_non_const_min_t = ((__T2148 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43296_381_non_const_min_t, __T2148))); __cuda_local_var_43296_401_non_const_max_t = ((__T2149 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43296_401_non_const_max_t, __T2149))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43296_401_non_const_max_t - __cuda_local_var_43296_381_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43296_401_non_const_max_t - __cuda_local_var_43296_381_non_const_min_t)))); } while (0); __T2147:;
do {  enum cudaError __cuda_local_var_43297_163_non_const_error;
# 330 "pipeline.cu"
 unsigned __cuda_local_var_43297_381_non_const_min_t;
# 330 "pipeline.cu"
 unsigned __cuda_local_var_43297_401_non_const_max_t;
# 330 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_SHL_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_SHL_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43297_163_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43297_163_non_const_error))); goto __T2150; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43297_381_non_const_min_t = 4294967295U; __cuda_local_var_43297_401_non_const_max_t = 0U; {  int i;
# 330 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2151;
 unsigned __T2152;
# 330 "pipeline.cu"
__cuda_local_var_43297_381_non_const_min_t = ((__T2151 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43297_381_non_const_min_t, __T2151))); __cuda_local_var_43297_401_non_const_max_t = ((__T2152 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43297_401_non_const_max_t, __T2152))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43297_401_non_const_max_t - __cuda_local_var_43297_381_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43297_401_non_const_max_t - __cuda_local_var_43297_381_non_const_min_t)))); } while (0); __T2150:;
do {  enum cudaError __cuda_local_var_43298_163_non_const_error;
# 331 "pipeline.cu"
 unsigned __cuda_local_var_43298_381_non_const_min_t;
# 331 "pipeline.cu"
 unsigned __cuda_local_var_43298_401_non_const_max_t;
# 331 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_SHR_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_SHR_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43298_163_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43298_163_non_const_error))); goto __T2153; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43298_381_non_const_min_t = 4294967295U; __cuda_local_var_43298_401_non_const_max_t = 0U; {  int i;
# 331 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2154;
 unsigned __T2155;
# 331 "pipeline.cu"
__cuda_local_var_43298_381_non_const_min_t = ((__T2154 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43298_381_non_const_min_t, __T2154))); __cuda_local_var_43298_401_non_const_max_t = ((__T2155 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43298_401_non_const_max_t, __T2155))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43298_401_non_const_max_t - __cuda_local_var_43298_381_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43298_401_non_const_max_t - __cuda_local_var_43298_381_non_const_min_t)))); } while (0); __T2153:;
printf(((const char *)"\n"));



do {  enum cudaError __cuda_local_var_43303_111_non_const_error;
# 336 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z20K_UMUL24_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_UMUL24_UINT_DEP128"))); if (((int)(__cuda_local_var_43303_111_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43303_111_non_const_error))); goto __T2156; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2156:;
do {  enum cudaError __cuda_local_var_43304_109_non_const_error;
# 337 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_MUL24_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MUL24_INT_DEP128"))); if (((int)(__cuda_local_var_43304_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43304_109_non_const_error))); goto __T2157; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2157:;
do {  enum cudaError __cuda_local_var_43305_111_non_const_error;
# 338 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z20K_UMULHI_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_UMULHI_UINT_DEP128"))); if (((int)(__cuda_local_var_43305_111_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43305_111_non_const_error))); goto __T2158; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2158:;
do {  enum cudaError __cuda_local_var_43306_109_non_const_error;
# 339 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_MULHI_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MULHI_INT_DEP128"))); if (((int)(__cuda_local_var_43306_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43306_109_non_const_error))); goto __T2159; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2159:;
do {  enum cudaError __cuda_local_var_43307_109_non_const_error;
# 340 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_USAD_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_USAD_UINT_DEP128"))); if (((int)(__cuda_local_var_43307_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43307_109_non_const_error))); goto __T2160; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2160:;
do {  enum cudaError __cuda_local_var_43308_107_non_const_error;
# 341 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_SAD_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SAD_INT_DEP128"))); if (((int)(__cuda_local_var_43308_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43308_107_non_const_error))); goto __T2161; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2161:;

do {  enum cudaError __cuda_local_var_43310_169_non_const_error;
# 343 "pipeline.cu"
 unsigned __cuda_local_var_43310_387_non_const_min_t;
# 343 "pipeline.cu"
 unsigned __cuda_local_var_43310_407_non_const_max_t;
# 343 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_UMUL24_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z20K_UMUL24_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43310_169_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43310_169_non_const_error))); goto __T2162; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43310_387_non_const_min_t = 4294967295U; __cuda_local_var_43310_407_non_const_max_t = 0U; {  int i;
# 343 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2163;
 unsigned __T2164;
# 343 "pipeline.cu"
__cuda_local_var_43310_387_non_const_min_t = ((__T2163 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43310_387_non_const_min_t, __T2163))); __cuda_local_var_43310_407_non_const_max_t = ((__T2164 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43310_407_non_const_max_t, __T2164))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43310_407_non_const_max_t - __cuda_local_var_43310_387_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43310_407_non_const_max_t - __cuda_local_var_43310_387_non_const_min_t)))); } while (0); __T2162:;
do {  enum cudaError __cuda_local_var_43311_165_non_const_error;
# 344 "pipeline.cu"
 unsigned __cuda_local_var_43311_383_non_const_min_t;
# 344 "pipeline.cu"
 unsigned __cuda_local_var_43311_403_non_const_max_t;
# 344 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MUL24_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_MUL24_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43311_165_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43311_165_non_const_error))); goto __T2165; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43311_383_non_const_min_t = 4294967295U; __cuda_local_var_43311_403_non_const_max_t = 0U; {  int i;
# 344 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2166;
 unsigned __T2167;
# 344 "pipeline.cu"
__cuda_local_var_43311_383_non_const_min_t = ((__T2166 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43311_383_non_const_min_t, __T2166))); __cuda_local_var_43311_403_non_const_max_t = ((__T2167 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43311_403_non_const_max_t, __T2167))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43311_403_non_const_max_t - __cuda_local_var_43311_383_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43311_403_non_const_max_t - __cuda_local_var_43311_383_non_const_min_t)))); } while (0); __T2165:;
do {  enum cudaError __cuda_local_var_43312_169_non_const_error;
# 345 "pipeline.cu"
 unsigned __cuda_local_var_43312_387_non_const_min_t;
# 345 "pipeline.cu"
 unsigned __cuda_local_var_43312_407_non_const_max_t;
# 345 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_UMULHI_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z20K_UMULHI_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43312_169_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43312_169_non_const_error))); goto __T2168; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43312_387_non_const_min_t = 4294967295U; __cuda_local_var_43312_407_non_const_max_t = 0U; {  int i;
# 345 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2169;
 unsigned __T2170;
# 345 "pipeline.cu"
__cuda_local_var_43312_387_non_const_min_t = ((__T2169 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43312_387_non_const_min_t, __T2169))); __cuda_local_var_43312_407_non_const_max_t = ((__T2170 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43312_407_non_const_max_t, __T2170))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43312_407_non_const_max_t - __cuda_local_var_43312_387_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43312_407_non_const_max_t - __cuda_local_var_43312_387_non_const_min_t)))); } while (0); __T2168:;
do {  enum cudaError __cuda_local_var_43313_165_non_const_error;
# 346 "pipeline.cu"
 unsigned __cuda_local_var_43313_383_non_const_min_t;
# 346 "pipeline.cu"
 unsigned __cuda_local_var_43313_403_non_const_max_t;
# 346 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MULHI_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_MULHI_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43313_165_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43313_165_non_const_error))); goto __T2171; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43313_383_non_const_min_t = 4294967295U; __cuda_local_var_43313_403_non_const_max_t = 0U; {  int i;
# 346 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2172;
 unsigned __T2173;
# 346 "pipeline.cu"
__cuda_local_var_43313_383_non_const_min_t = ((__T2172 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43313_383_non_const_min_t, __T2172))); __cuda_local_var_43313_403_non_const_max_t = ((__T2173 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43313_403_non_const_max_t, __T2173))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43313_403_non_const_max_t - __cuda_local_var_43313_383_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43313_403_non_const_max_t - __cuda_local_var_43313_383_non_const_min_t)))); } while (0); __T2171:;
do {  enum cudaError __cuda_local_var_43314_165_non_const_error;
# 347 "pipeline.cu"
 unsigned __cuda_local_var_43314_383_non_const_min_t;
# 347 "pipeline.cu"
 unsigned __cuda_local_var_43314_403_non_const_max_t;
# 347 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_USAD_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_USAD_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43314_165_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43314_165_non_const_error))); goto __T2174; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43314_383_non_const_min_t = 4294967295U; __cuda_local_var_43314_403_non_const_max_t = 0U; {  int i;
# 347 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2175;
 unsigned __T2176;
# 347 "pipeline.cu"
__cuda_local_var_43314_383_non_const_min_t = ((__T2175 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43314_383_non_const_min_t, __T2175))); __cuda_local_var_43314_403_non_const_max_t = ((__T2176 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43314_403_non_const_max_t, __T2176))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43314_403_non_const_max_t - __cuda_local_var_43314_383_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43314_403_non_const_max_t - __cuda_local_var_43314_383_non_const_min_t)))); } while (0); __T2174:;
do {  enum cudaError __cuda_local_var_43315_161_non_const_error;
# 348 "pipeline.cu"
 unsigned __cuda_local_var_43315_379_non_const_min_t;
# 348 "pipeline.cu"
 unsigned __cuda_local_var_43315_399_non_const_max_t;
# 348 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_SAD_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z16K_SAD_INT_DEP128PjS_iii(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43315_161_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43315_161_non_const_error))); goto __T2177; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43315_379_non_const_min_t = 4294967295U; __cuda_local_var_43315_399_non_const_max_t = 0U; {  int i;
# 348 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2178;
 unsigned __T2179;
# 348 "pipeline.cu"
__cuda_local_var_43315_379_non_const_min_t = ((__T2178 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43315_379_non_const_min_t, __T2178))); __cuda_local_var_43315_399_non_const_max_t = ((__T2179 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43315_399_non_const_max_t, __T2179))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43315_399_non_const_max_t - __cuda_local_var_43315_379_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43315_399_non_const_max_t - __cuda_local_var_43315_379_non_const_min_t)))); } while (0); __T2177:;
printf(((const char *)"\n"));


do {  enum cudaError __cuda_local_var_43319_113_non_const_error;
# 352 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z22K_FADD_RN_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_FADD_RN_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43319_113_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43319_113_non_const_error))); goto __T2180; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2180:;
do {  enum cudaError __cuda_local_var_43320_113_non_const_error;
# 353 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z22K_FADD_RZ_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_FADD_RZ_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43320_113_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43320_113_non_const_error))); goto __T2181; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2181:;
do {  enum cudaError __cuda_local_var_43321_113_non_const_error;
# 354 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z22K_FMUL_RN_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_FMUL_RN_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43321_113_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43321_113_non_const_error))); goto __T2182; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2182:;
do {  enum cudaError __cuda_local_var_43322_113_non_const_error;
# 355 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z22K_FMUL_RZ_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_FMUL_RZ_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43322_113_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43322_113_non_const_error))); goto __T2183; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2183:;
do {  enum cudaError __cuda_local_var_43323_114_non_const_error;
# 356 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z23K_FDIVIDEF_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_FDIVIDEF_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43323_114_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43323_114_non_const_error))); goto __T2184; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2184:;

do {  enum cudaError __cuda_local_var_43325_173_non_const_error;
# 358 "pipeline.cu"
 unsigned __cuda_local_var_43325_391_non_const_min_t;
# 358 "pipeline.cu"
 unsigned __cuda_local_var_43325_411_non_const_max_t;
# 358 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_FADD_RN_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z22K_FADD_RN_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43325_173_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43325_173_non_const_error))); goto __T2185; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43325_391_non_const_min_t = 4294967295U; __cuda_local_var_43325_411_non_const_max_t = 0U; {  int i;
# 358 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2186;
 unsigned __T2187;
# 358 "pipeline.cu"
__cuda_local_var_43325_391_non_const_min_t = ((__T2186 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43325_391_non_const_min_t, __T2186))); __cuda_local_var_43325_411_non_const_max_t = ((__T2187 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43325_411_non_const_max_t, __T2187))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43325_411_non_const_max_t - __cuda_local_var_43325_391_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43325_411_non_const_max_t - __cuda_local_var_43325_391_non_const_min_t)))); } while (0); __T2185:;
do {  enum cudaError __cuda_local_var_43326_173_non_const_error;
# 359 "pipeline.cu"
 unsigned __cuda_local_var_43326_391_non_const_min_t;
# 359 "pipeline.cu"
 unsigned __cuda_local_var_43326_411_non_const_max_t;
# 359 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_FADD_RZ_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z22K_FADD_RZ_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43326_173_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43326_173_non_const_error))); goto __T2188; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43326_391_non_const_min_t = 4294967295U; __cuda_local_var_43326_411_non_const_max_t = 0U; {  int i;
# 359 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2189;
 unsigned __T2190;
# 359 "pipeline.cu"
__cuda_local_var_43326_391_non_const_min_t = ((__T2189 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43326_391_non_const_min_t, __T2189))); __cuda_local_var_43326_411_non_const_max_t = ((__T2190 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43326_411_non_const_max_t, __T2190))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43326_411_non_const_max_t - __cuda_local_var_43326_391_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43326_411_non_const_max_t - __cuda_local_var_43326_391_non_const_min_t)))); } while (0); __T2188:;
do {  enum cudaError __cuda_local_var_43327_173_non_const_error;
# 360 "pipeline.cu"
 unsigned __cuda_local_var_43327_391_non_const_min_t;
# 360 "pipeline.cu"
 unsigned __cuda_local_var_43327_411_non_const_max_t;
# 360 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_FMUL_RN_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z22K_FMUL_RN_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43327_173_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43327_173_non_const_error))); goto __T2191; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43327_391_non_const_min_t = 4294967295U; __cuda_local_var_43327_411_non_const_max_t = 0U; {  int i;
# 360 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2192;
 unsigned __T2193;
# 360 "pipeline.cu"
__cuda_local_var_43327_391_non_const_min_t = ((__T2192 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43327_391_non_const_min_t, __T2192))); __cuda_local_var_43327_411_non_const_max_t = ((__T2193 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43327_411_non_const_max_t, __T2193))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43327_411_non_const_max_t - __cuda_local_var_43327_391_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43327_411_non_const_max_t - __cuda_local_var_43327_391_non_const_min_t)))); } while (0); __T2191:;
do {  enum cudaError __cuda_local_var_43328_173_non_const_error;
# 361 "pipeline.cu"
 unsigned __cuda_local_var_43328_391_non_const_min_t;
# 361 "pipeline.cu"
 unsigned __cuda_local_var_43328_411_non_const_max_t;
# 361 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_FMUL_RZ_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z22K_FMUL_RZ_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43328_173_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43328_173_non_const_error))); goto __T2194; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43328_391_non_const_min_t = 4294967295U; __cuda_local_var_43328_411_non_const_max_t = 0U; {  int i;
# 361 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2195;
 unsigned __T2196;
# 361 "pipeline.cu"
__cuda_local_var_43328_391_non_const_min_t = ((__T2195 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43328_391_non_const_min_t, __T2195))); __cuda_local_var_43328_411_non_const_max_t = ((__T2196 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43328_411_non_const_max_t, __T2196))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43328_411_non_const_max_t - __cuda_local_var_43328_391_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43328_411_non_const_max_t - __cuda_local_var_43328_391_non_const_min_t)))); } while (0); __T2194:;
do {  enum cudaError __cuda_local_var_43329_175_non_const_error;
# 362 "pipeline.cu"
 unsigned __cuda_local_var_43329_393_non_const_min_t;
# 362 "pipeline.cu"
 unsigned __cuda_local_var_43329_413_non_const_max_t;
# 362 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_FDIVIDEF_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z23K_FDIVIDEF_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43329_175_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43329_175_non_const_error))); goto __T2197; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43329_393_non_const_min_t = 4294967295U; __cuda_local_var_43329_413_non_const_max_t = 0U; {  int i;
# 362 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2198;
 unsigned __T2199;
# 362 "pipeline.cu"
__cuda_local_var_43329_393_non_const_min_t = ((__T2198 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43329_393_non_const_min_t, __T2198))); __cuda_local_var_43329_413_non_const_max_t = ((__T2199 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43329_413_non_const_max_t, __T2199))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43329_413_non_const_max_t - __cuda_local_var_43329_393_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43329_413_non_const_max_t - __cuda_local_var_43329_393_non_const_min_t)))); } while (0); __T2197:;
printf(((const char *)"\n"));


do {  enum cudaError __cuda_local_var_43333_114_non_const_error;
# 366 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z23K_DADD_RN_DOUBLE_DEP128PjS_ddi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_DADD_RN_DOUBLE_DEP128"))); if (((int)(__cuda_local_var_43333_114_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43333_114_non_const_error))); goto __T2200; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2200:;

do {  enum cudaError __cuda_local_var_43335_175_non_const_error;
# 368 "pipeline.cu"
 unsigned __cuda_local_var_43335_393_non_const_min_t;
# 368 "pipeline.cu"
 unsigned __cuda_local_var_43335_413_non_const_max_t;
# 368 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_DADD_RN_DOUBLE_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z23K_DADD_RN_DOUBLE_DEP128PjS_ddi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43335_175_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43335_175_non_const_error))); goto __T2201; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43335_393_non_const_min_t = 4294967295U; __cuda_local_var_43335_413_non_const_max_t = 0U; {  int i;
# 368 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2202;
 unsigned __T2203;
# 368 "pipeline.cu"
__cuda_local_var_43335_393_non_const_min_t = ((__T2202 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43335_393_non_const_min_t, __T2202))); __cuda_local_var_43335_413_non_const_max_t = ((__T2203 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43335_413_non_const_max_t, __T2203))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43335_413_non_const_max_t - __cuda_local_var_43335_393_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43335_413_non_const_max_t - __cuda_local_var_43335_393_non_const_min_t)))); } while (0); __T2201:;
printf(((const char *)"\n"));



do {  enum cudaError __cuda_local_var_43340_109_non_const_error;
# 373 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_RCP_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_RCP_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43340_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43340_109_non_const_error))); goto __T2204; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2204:;
do {  enum cudaError __cuda_local_var_43341_110_non_const_error;
# 374 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_SQRT_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SQRT_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43341_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43341_110_non_const_error))); goto __T2205; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2205:;
do {  enum cudaError __cuda_local_var_43342_111_non_const_error;
# 375 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z20K_RSQRT_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_RSQRT_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43342_111_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43342_111_non_const_error))); goto __T2206; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2206:;
# 389 "pipeline.cu"
do {  enum cudaError __cuda_local_var_43344_165_non_const_error;
# 389 "pipeline.cu"
 unsigned __cuda_local_var_43344_383_non_const_min_t;
# 389 "pipeline.cu"
 unsigned __cuda_local_var_43344_403_non_const_max_t;
# 389 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_RCP_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_RCP_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43344_165_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43344_165_non_const_error))); goto __T2207; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43344_383_non_const_min_t = 4294967295U; __cuda_local_var_43344_403_non_const_max_t = 0U; {  int i;
# 389 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2208;
 unsigned __T2209;
# 389 "pipeline.cu"
__cuda_local_var_43344_383_non_const_min_t = ((__T2208 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43344_383_non_const_min_t, __T2208))); __cuda_local_var_43344_403_non_const_max_t = ((__T2209 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43344_403_non_const_max_t, __T2209))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43344_403_non_const_max_t - __cuda_local_var_43344_383_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43344_403_non_const_max_t - __cuda_local_var_43344_383_non_const_min_t)))); } while (0); __T2207:;
do {  enum cudaError __cuda_local_var_43345_167_non_const_error;
# 390 "pipeline.cu"
 unsigned __cuda_local_var_43345_385_non_const_min_t;
# 390 "pipeline.cu"
 unsigned __cuda_local_var_43345_405_non_const_max_t;
# 390 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_SQRT_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_SQRT_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43345_167_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43345_167_non_const_error))); goto __T2210; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43345_385_non_const_min_t = 4294967295U; __cuda_local_var_43345_405_non_const_max_t = 0U; {  int i;
# 390 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2211;
 unsigned __T2212;
# 390 "pipeline.cu"
__cuda_local_var_43345_385_non_const_min_t = ((__T2211 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43345_385_non_const_min_t, __T2211))); __cuda_local_var_43345_405_non_const_max_t = ((__T2212 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43345_405_non_const_max_t, __T2212))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43345_405_non_const_max_t - __cuda_local_var_43345_385_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43345_405_non_const_max_t - __cuda_local_var_43345_385_non_const_min_t)))); } while (0); __T2210:;
do {  enum cudaError __cuda_local_var_43346_169_non_const_error;
# 391 "pipeline.cu"
 unsigned __cuda_local_var_43346_387_non_const_min_t;
# 391 "pipeline.cu"
 unsigned __cuda_local_var_43346_407_non_const_max_t;
# 391 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_RSQRT_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z20K_RSQRT_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43346_169_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43346_169_non_const_error))); goto __T2213; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43346_387_non_const_min_t = 4294967295U; __cuda_local_var_43346_407_non_const_max_t = 0U; {  int i;
# 391 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2214;
 unsigned __T2215;
# 391 "pipeline.cu"
__cuda_local_var_43346_387_non_const_min_t = ((__T2214 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43346_387_non_const_min_t, __T2214))); __cuda_local_var_43346_407_non_const_max_t = ((__T2215 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43346_407_non_const_max_t, __T2215))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43346_407_non_const_max_t - __cuda_local_var_43346_387_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43346_407_non_const_max_t - __cuda_local_var_43346_387_non_const_min_t)))); } while (0); __T2213:;
# 403 "pipeline.cu"
printf(((const char *)"\n"));



do {  enum cudaError __cuda_local_var_43352_110_non_const_error;
# 407 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_SINF_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SINF_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43352_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43352_110_non_const_error))); goto __T2216; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2216:;
do {  enum cudaError __cuda_local_var_43353_110_non_const_error;
# 408 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_COSF_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_COSF_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43353_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43353_110_non_const_error))); goto __T2217; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2217:;
do {  enum cudaError __cuda_local_var_43354_110_non_const_error;
# 409 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_TANF_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_TANF_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43354_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43354_110_non_const_error))); goto __T2218; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2218:;
do {  enum cudaError __cuda_local_var_43355_110_non_const_error;
# 410 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_EXPF_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_EXPF_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43355_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43355_110_non_const_error))); goto __T2219; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2219:;
do {  enum cudaError __cuda_local_var_43356_111_non_const_error;
# 411 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z20K_EXP2F_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_EXP2F_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43356_111_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43356_111_non_const_error))); goto __T2220; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2220:;
do {  enum cudaError __cuda_local_var_43357_112_non_const_error;
# 412 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z21K_EXP10F_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_EXP10F_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43357_112_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43357_112_non_const_error))); goto __T2221; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2221:;
do {  enum cudaError __cuda_local_var_43358_110_non_const_error;
# 413 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_LOGF_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_LOGF_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43358_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43358_110_non_const_error))); goto __T2222; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2222:;
do {  enum cudaError __cuda_local_var_43359_111_non_const_error;
# 414 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z20K_LOG2F_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_LOG2F_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43359_111_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43359_111_non_const_error))); goto __T2223; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2223:;
do {  enum cudaError __cuda_local_var_43360_112_non_const_error;
# 415 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z21K_LOG10F_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_LOG10F_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43360_112_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43360_112_non_const_error))); goto __T2224; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2224:;
do {  enum cudaError __cuda_local_var_43361_110_non_const_error;
# 416 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_POWF_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_POWF_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43361_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43361_110_non_const_error))); goto __T2225; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2225:;

do {  enum cudaError __cuda_local_var_43363_167_non_const_error;
# 418 "pipeline.cu"
 unsigned __cuda_local_var_43363_385_non_const_min_t;
# 418 "pipeline.cu"
 unsigned __cuda_local_var_43363_405_non_const_max_t;
# 418 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_SINF_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_SINF_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43363_167_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43363_167_non_const_error))); goto __T2226; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43363_385_non_const_min_t = 4294967295U; __cuda_local_var_43363_405_non_const_max_t = 0U; {  int i;
# 418 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2227;
 unsigned __T2228;
# 418 "pipeline.cu"
__cuda_local_var_43363_385_non_const_min_t = ((__T2227 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43363_385_non_const_min_t, __T2227))); __cuda_local_var_43363_405_non_const_max_t = ((__T2228 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43363_405_non_const_max_t, __T2228))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43363_405_non_const_max_t - __cuda_local_var_43363_385_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43363_405_non_const_max_t - __cuda_local_var_43363_385_non_const_min_t)))); } while (0); __T2226:;
do {  enum cudaError __cuda_local_var_43364_167_non_const_error;
# 419 "pipeline.cu"
 unsigned __cuda_local_var_43364_385_non_const_min_t;
# 419 "pipeline.cu"
 unsigned __cuda_local_var_43364_405_non_const_max_t;
# 419 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_COSF_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_COSF_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43364_167_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43364_167_non_const_error))); goto __T2229; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43364_385_non_const_min_t = 4294967295U; __cuda_local_var_43364_405_non_const_max_t = 0U; {  int i;
# 419 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2230;
 unsigned __T2231;
# 419 "pipeline.cu"
__cuda_local_var_43364_385_non_const_min_t = ((__T2230 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43364_385_non_const_min_t, __T2230))); __cuda_local_var_43364_405_non_const_max_t = ((__T2231 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43364_405_non_const_max_t, __T2231))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43364_405_non_const_max_t - __cuda_local_var_43364_385_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43364_405_non_const_max_t - __cuda_local_var_43364_385_non_const_min_t)))); } while (0); __T2229:;
do {  enum cudaError __cuda_local_var_43365_167_non_const_error;
# 420 "pipeline.cu"
 unsigned __cuda_local_var_43365_385_non_const_min_t;
# 420 "pipeline.cu"
 unsigned __cuda_local_var_43365_405_non_const_max_t;
# 420 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_TANF_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_TANF_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43365_167_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43365_167_non_const_error))); goto __T2232; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43365_385_non_const_min_t = 4294967295U; __cuda_local_var_43365_405_non_const_max_t = 0U; {  int i;
# 420 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2233;
 unsigned __T2234;
# 420 "pipeline.cu"
__cuda_local_var_43365_385_non_const_min_t = ((__T2233 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43365_385_non_const_min_t, __T2233))); __cuda_local_var_43365_405_non_const_max_t = ((__T2234 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43365_405_non_const_max_t, __T2234))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43365_405_non_const_max_t - __cuda_local_var_43365_385_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43365_405_non_const_max_t - __cuda_local_var_43365_385_non_const_min_t)))); } while (0); __T2232:;
do {  enum cudaError __cuda_local_var_43366_167_non_const_error;
# 421 "pipeline.cu"
 unsigned __cuda_local_var_43366_385_non_const_min_t;
# 421 "pipeline.cu"
 unsigned __cuda_local_var_43366_405_non_const_max_t;
# 421 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_EXPF_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_EXPF_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43366_167_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43366_167_non_const_error))); goto __T2235; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43366_385_non_const_min_t = 4294967295U; __cuda_local_var_43366_405_non_const_max_t = 0U; {  int i;
# 421 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2236;
 unsigned __T2237;
# 421 "pipeline.cu"
__cuda_local_var_43366_385_non_const_min_t = ((__T2236 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43366_385_non_const_min_t, __T2236))); __cuda_local_var_43366_405_non_const_max_t = ((__T2237 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43366_405_non_const_max_t, __T2237))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43366_405_non_const_max_t - __cuda_local_var_43366_385_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43366_405_non_const_max_t - __cuda_local_var_43366_385_non_const_min_t)))); } while (0); __T2235:;
do {  enum cudaError __cuda_local_var_43367_169_non_const_error;
# 422 "pipeline.cu"
 unsigned __cuda_local_var_43367_387_non_const_min_t;
# 422 "pipeline.cu"
 unsigned __cuda_local_var_43367_407_non_const_max_t;
# 422 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_EXP2F_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z20K_EXP2F_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43367_169_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43367_169_non_const_error))); goto __T2238; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43367_387_non_const_min_t = 4294967295U; __cuda_local_var_43367_407_non_const_max_t = 0U; {  int i;
# 422 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2239;
 unsigned __T2240;
# 422 "pipeline.cu"
__cuda_local_var_43367_387_non_const_min_t = ((__T2239 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43367_387_non_const_min_t, __T2239))); __cuda_local_var_43367_407_non_const_max_t = ((__T2240 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43367_407_non_const_max_t, __T2240))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43367_407_non_const_max_t - __cuda_local_var_43367_387_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43367_407_non_const_max_t - __cuda_local_var_43367_387_non_const_min_t)))); } while (0); __T2238:;
do {  enum cudaError __cuda_local_var_43368_171_non_const_error;
# 423 "pipeline.cu"
 unsigned __cuda_local_var_43368_389_non_const_min_t;
# 423 "pipeline.cu"
 unsigned __cuda_local_var_43368_409_non_const_max_t;
# 423 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_EXP10F_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z21K_EXP10F_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43368_171_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43368_171_non_const_error))); goto __T2241; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43368_389_non_const_min_t = 4294967295U; __cuda_local_var_43368_409_non_const_max_t = 0U; {  int i;
# 423 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2242;
 unsigned __T2243;
# 423 "pipeline.cu"
__cuda_local_var_43368_389_non_const_min_t = ((__T2242 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43368_389_non_const_min_t, __T2242))); __cuda_local_var_43368_409_non_const_max_t = ((__T2243 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43368_409_non_const_max_t, __T2243))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43368_409_non_const_max_t - __cuda_local_var_43368_389_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43368_409_non_const_max_t - __cuda_local_var_43368_389_non_const_min_t)))); } while (0); __T2241:;
do {  enum cudaError __cuda_local_var_43369_167_non_const_error;
# 424 "pipeline.cu"
 unsigned __cuda_local_var_43369_385_non_const_min_t;
# 424 "pipeline.cu"
 unsigned __cuda_local_var_43369_405_non_const_max_t;
# 424 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_LOGF_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_LOGF_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43369_167_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43369_167_non_const_error))); goto __T2244; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43369_385_non_const_min_t = 4294967295U; __cuda_local_var_43369_405_non_const_max_t = 0U; {  int i;
# 424 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2245;
 unsigned __T2246;
# 424 "pipeline.cu"
__cuda_local_var_43369_385_non_const_min_t = ((__T2245 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43369_385_non_const_min_t, __T2245))); __cuda_local_var_43369_405_non_const_max_t = ((__T2246 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43369_405_non_const_max_t, __T2246))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43369_405_non_const_max_t - __cuda_local_var_43369_385_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43369_405_non_const_max_t - __cuda_local_var_43369_385_non_const_min_t)))); } while (0); __T2244:;
do {  enum cudaError __cuda_local_var_43370_169_non_const_error;
# 425 "pipeline.cu"
 unsigned __cuda_local_var_43370_387_non_const_min_t;
# 425 "pipeline.cu"
 unsigned __cuda_local_var_43370_407_non_const_max_t;
# 425 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_LOG2F_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z20K_LOG2F_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43370_169_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43370_169_non_const_error))); goto __T2247; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43370_387_non_const_min_t = 4294967295U; __cuda_local_var_43370_407_non_const_max_t = 0U; {  int i;
# 425 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2248;
 unsigned __T2249;
# 425 "pipeline.cu"
__cuda_local_var_43370_387_non_const_min_t = ((__T2248 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43370_387_non_const_min_t, __T2248))); __cuda_local_var_43370_407_non_const_max_t = ((__T2249 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43370_407_non_const_max_t, __T2249))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43370_407_non_const_max_t - __cuda_local_var_43370_387_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43370_407_non_const_max_t - __cuda_local_var_43370_387_non_const_min_t)))); } while (0); __T2247:;
do {  enum cudaError __cuda_local_var_43371_171_non_const_error;
# 426 "pipeline.cu"
 unsigned __cuda_local_var_43371_389_non_const_min_t;
# 426 "pipeline.cu"
 unsigned __cuda_local_var_43371_409_non_const_max_t;
# 426 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_LOG10F_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z21K_LOG10F_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43371_171_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43371_171_non_const_error))); goto __T2250; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43371_389_non_const_min_t = 4294967295U; __cuda_local_var_43371_409_non_const_max_t = 0U; {  int i;
# 426 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2251;
 unsigned __T2252;
# 426 "pipeline.cu"
__cuda_local_var_43371_389_non_const_min_t = ((__T2251 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43371_389_non_const_min_t, __T2251))); __cuda_local_var_43371_409_non_const_max_t = ((__T2252 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43371_409_non_const_max_t, __T2252))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43371_409_non_const_max_t - __cuda_local_var_43371_389_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43371_409_non_const_max_t - __cuda_local_var_43371_389_non_const_min_t)))); } while (0); __T2250:;
do {  enum cudaError __cuda_local_var_43372_167_non_const_error;
# 427 "pipeline.cu"
 unsigned __cuda_local_var_43372_385_non_const_min_t;
# 427 "pipeline.cu"
 unsigned __cuda_local_var_43372_405_non_const_max_t;
# 427 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_POWF_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z19K_POWF_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43372_167_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43372_167_non_const_error))); goto __T2253; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43372_385_non_const_min_t = 4294967295U; __cuda_local_var_43372_405_non_const_max_t = 0U; {  int i;
# 427 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2254;
 unsigned __T2255;
# 427 "pipeline.cu"
__cuda_local_var_43372_385_non_const_min_t = ((__T2254 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43372_385_non_const_min_t, __T2254))); __cuda_local_var_43372_405_non_const_max_t = ((__T2255 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43372_405_non_const_max_t, __T2255))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43372_405_non_const_max_t - __cuda_local_var_43372_385_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43372_405_non_const_max_t - __cuda_local_var_43372_385_non_const_min_t)))); } while (0); __T2253:;
printf(((const char *)"\n"));


do {  enum cudaError __cuda_local_var_43376_115_non_const_error;
# 431 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z24K_INTASFLOAT_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_INTASFLOAT_UINT_DEP128"))); if (((int)(__cuda_local_var_43376_115_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43376_115_non_const_error))); goto __T2256; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2256:;
do {  enum cudaError __cuda_local_var_43377_116_non_const_error;
# 432 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z25K_FLOATASINT_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_FLOATASINT_FLOAT_DEP128"))); if (((int)(__cuda_local_var_43377_116_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43377_116_non_const_error))); goto __T2257; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2257:;

do {  enum cudaError __cuda_local_var_43379_177_non_const_error;
# 434 "pipeline.cu"
 unsigned __cuda_local_var_43379_395_non_const_min_t;
# 434 "pipeline.cu"
 unsigned __cuda_local_var_43379_415_non_const_max_t;
# 434 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_INTASFLOAT_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z24K_INTASFLOAT_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43379_177_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43379_177_non_const_error))); goto __T2258; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43379_395_non_const_min_t = 4294967295U; __cuda_local_var_43379_415_non_const_max_t = 0U; {  int i;
# 434 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2259;
 unsigned __T2260;
# 434 "pipeline.cu"
__cuda_local_var_43379_395_non_const_min_t = ((__T2259 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43379_395_non_const_min_t, __T2259))); __cuda_local_var_43379_415_non_const_max_t = ((__T2260 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43379_415_non_const_max_t, __T2260))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43379_415_non_const_max_t - __cuda_local_var_43379_395_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43379_415_non_const_max_t - __cuda_local_var_43379_395_non_const_min_t)))); } while (0); __T2258:;
do {  enum cudaError __cuda_local_var_43380_179_non_const_error;
# 435 "pipeline.cu"
 unsigned __cuda_local_var_43380_397_non_const_min_t;
# 435 "pipeline.cu"
 unsigned __cuda_local_var_43380_417_non_const_max_t;
# 435 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_FLOATASINT_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z25K_FLOATASINT_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43380_179_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43380_179_non_const_error))); goto __T2261; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43380_397_non_const_min_t = 4294967295U; __cuda_local_var_43380_417_non_const_max_t = 0U; {  int i;
# 435 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2262;
 unsigned __T2263;
# 435 "pipeline.cu"
__cuda_local_var_43380_397_non_const_min_t = ((__T2262 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43380_397_non_const_min_t, __T2262))); __cuda_local_var_43380_417_non_const_max_t = ((__T2263 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43380_417_non_const_max_t, __T2263))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43380_417_non_const_max_t - __cuda_local_var_43380_397_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43380_417_non_const_max_t - __cuda_local_var_43380_397_non_const_min_t)))); } while (0); __T2261:;
printf(((const char *)"\n"));



do {  enum cudaError __cuda_local_var_43385_109_non_const_error;
# 440 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_POPC_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_POPC_UINT_DEP128"))); if (((int)(__cuda_local_var_43385_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43385_109_non_const_error))); goto __T2264; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2264:;
do {  enum cudaError __cuda_local_var_43386_108_non_const_error;
# 441 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_CLZ_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_CLZ_UINT_DEP128"))); if (((int)(__cuda_local_var_43386_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43386_108_non_const_error))); goto __T2265; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2265:;
printf(((const char *)"\n"));

do {  enum cudaError __cuda_local_var_43389_165_non_const_error;
# 444 "pipeline.cu"
 unsigned __cuda_local_var_43389_383_non_const_min_t;
# 444 "pipeline.cu"
 unsigned __cuda_local_var_43389_403_non_const_max_t;
# 444 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_POPC_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_POPC_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43389_165_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43389_165_non_const_error))); goto __T2266; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43389_383_non_const_min_t = 4294967295U; __cuda_local_var_43389_403_non_const_max_t = 0U; {  int i;
# 444 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2267;
 unsigned __T2268;
# 444 "pipeline.cu"
__cuda_local_var_43389_383_non_const_min_t = ((__T2267 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43389_383_non_const_min_t, __T2267))); __cuda_local_var_43389_403_non_const_max_t = ((__T2268 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43389_403_non_const_max_t, __T2268))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43389_403_non_const_max_t - __cuda_local_var_43389_383_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43389_403_non_const_max_t - __cuda_local_var_43389_383_non_const_min_t)))); } while (0); __T2266:;
do {  enum cudaError __cuda_local_var_43390_163_non_const_error;
# 445 "pipeline.cu"
 unsigned __cuda_local_var_43390_381_non_const_min_t;
# 445 "pipeline.cu"
 unsigned __cuda_local_var_43390_401_non_const_max_t;
# 445 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_CLZ_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_CLZ_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43390_163_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43390_163_non_const_error))); goto __T2269; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43390_381_non_const_min_t = 4294967295U; __cuda_local_var_43390_401_non_const_max_t = 0U; {  int i;
# 445 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2270;
 unsigned __T2271;
# 445 "pipeline.cu"
__cuda_local_var_43390_381_non_const_min_t = ((__T2270 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43390_381_non_const_min_t, __T2270))); __cuda_local_var_43390_401_non_const_max_t = ((__T2271 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43390_401_non_const_max_t, __T2271))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43390_401_non_const_max_t - __cuda_local_var_43390_381_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43390_401_non_const_max_t - __cuda_local_var_43390_381_non_const_min_t)))); } while (0); __T2269:;
printf(((const char *)"\n"));




do {  enum cudaError __cuda_local_var_43396_108_non_const_error;
# 451 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_ALL_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_ALL_UINT_DEP128"))); if (((int)(__cuda_local_var_43396_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43396_108_non_const_error))); goto __T2272; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2272:;
do {  enum cudaError __cuda_local_var_43397_108_non_const_error;
# 452 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_ANY_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_ANY_UINT_DEP128"))); if (((int)(__cuda_local_var_43397_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43397_108_non_const_error))); goto __T2273; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2273:;
do {  enum cudaError __cuda_local_var_43398_109_non_const_error;
# 453 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (K_SYNC_UINT_DEP128(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SYNC_UINT_DEP128"))); if (((int)(__cuda_local_var_43398_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43398_109_non_const_error))); goto __T2274; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2274:;
printf(((const char *)"\n"));

do {  enum cudaError __cuda_local_var_43401_163_non_const_error;
# 456 "pipeline.cu"
 unsigned __cuda_local_var_43401_381_non_const_min_t;
# 456 "pipeline.cu"
 unsigned __cuda_local_var_43401_401_non_const_max_t;
# 456 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_ALL_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_ALL_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43401_163_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43401_163_non_const_error))); goto __T2275; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43401_381_non_const_min_t = 4294967295U; __cuda_local_var_43401_401_non_const_max_t = 0U; {  int i;
# 456 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2276;
 unsigned __T2277;
# 456 "pipeline.cu"
__cuda_local_var_43401_381_non_const_min_t = ((__T2276 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43401_381_non_const_min_t, __T2276))); __cuda_local_var_43401_401_non_const_max_t = ((__T2277 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43401_401_non_const_max_t, __T2277))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43401_401_non_const_max_t - __cuda_local_var_43401_381_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43401_401_non_const_max_t - __cuda_local_var_43401_381_non_const_min_t)))); } while (0); __T2275:;
do {  enum cudaError __cuda_local_var_43402_163_non_const_error;
# 457 "pipeline.cu"
 unsigned __cuda_local_var_43402_381_non_const_min_t;
# 457 "pipeline.cu"
 unsigned __cuda_local_var_43402_401_non_const_max_t;
# 457 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_ANY_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_ANY_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43402_163_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43402_163_non_const_error))); goto __T2278; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43402_381_non_const_min_t = 4294967295U; __cuda_local_var_43402_401_non_const_max_t = 0U; {  int i;
# 457 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2279;
 unsigned __T2280;
# 457 "pipeline.cu"
__cuda_local_var_43402_381_non_const_min_t = ((__T2279 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43402_381_non_const_min_t, __T2279))); __cuda_local_var_43402_401_non_const_max_t = ((__T2280 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43402_401_non_const_max_t, __T2280))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43402_401_non_const_max_t - __cuda_local_var_43402_381_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43402_401_non_const_max_t - __cuda_local_var_43402_381_non_const_min_t)))); } while (0); __T2278:;
do {  enum cudaError __cuda_local_var_43403_165_non_const_error;
# 458 "pipeline.cu"
 unsigned __cuda_local_var_43403_383_non_const_min_t;
# 458 "pipeline.cu"
 unsigned __cuda_local_var_43403_403_non_const_max_t;
# 458 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_SYNC_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (K_SYNC_UINT_DEP128(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43403_165_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43403_165_non_const_error))); goto __T2281; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43403_383_non_const_min_t = 4294967295U; __cuda_local_var_43403_403_non_const_max_t = 0U; {  int i;
# 458 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2282;
 unsigned __T2283;
# 458 "pipeline.cu"
__cuda_local_var_43403_383_non_const_min_t = ((__T2282 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43403_383_non_const_min_t, __T2282))); __cuda_local_var_43403_403_non_const_max_t = ((__T2283 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43403_403_non_const_max_t, __T2283))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43403_403_non_const_max_t - __cuda_local_var_43403_383_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43403_403_non_const_max_t - __cuda_local_var_43403_383_non_const_min_t)))); } while (0); __T2281:;
printf(((const char *)"\n"));


do { printf(((const char *)"\nPipeline latency/throughput with multiple warps (200 iterations of %d ops)\n"), 256); printf(((const char *)"  %s:\n"), ((const char *)("K_ADD_UINT_DEP128"))); for ((__cuda_local_var_43178_11_non_const_Db.x) = 1U; ((__cuda_local_var_43178_11_non_const_Db.x) <= 512U); (__cuda_local_var_43178_11_non_const_Db.x) += ((unsigned)(((__cuda_local_var_43178_11_non_const_Db.x) < 4U) ? 1 : (((__cuda_local_var_43178_11_non_const_Db.x) < 8U) ? 2 : (((__cuda_local_var_43178_11_non_const_Db.x) < 32U) ? 8 : 32))))) {  unsigned __cuda_local_var_43407_256_non_const_histogram[1024];
# 462 "pipeline.cu"
 unsigned __cuda_local_var_43407_292_non_const_sum_time;
# 462 "pipeline.cu"
 unsigned __cuda_local_var_43407_319_non_const_max_time;
# 462 "pipeline.cu"
 unsigned __cuda_local_var_43407_342_non_const_min_time;
# 462 "pipeline.cu"
 unsigned __cuda_local_var_43407_365_non_const_sum_max_time;
# 462 "pipeline.cu"
 char __cuda_local_var_43407_388_non_const_failed;
# 462 "pipeline.cu"
memset((char *)&__cuda_local_var_43407_256_non_const_histogram, 0,sizeof(__cuda_local_var_43407_256_non_const_histogram)); __cuda_local_var_43407_256_non_const_histogram[0] = 0U; __cuda_local_var_43407_292_non_const_sum_time = 0U; __cuda_local_var_43407_365_non_const_sum_max_time = 0U; __cuda_local_var_43407_388_non_const_failed = ((char)0); {  int i;
# 462 "pipeline.cu"
i = 0; for (; ((i < 200) && (!(__cuda_local_var_43407_388_non_const_failed))); i++) { cudaGetLastError(); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z17K_ADD_UINT_DEP128PjS_jji(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); if (((int)(cudaGetLastError())) != 0) { __cuda_local_var_43407_388_non_const_failed = ((char)1); goto __T2284; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43407_319_non_const_max_time = 0U; __cuda_local_var_43407_342_non_const_min_time = 4294967295U; {  int j;
# 462 "pipeline.cu"
j = 0; for (; (((unsigned)j) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); j += 64) {  unsigned __T2285;
 unsigned __T2286;
# 462 "pipeline.cu"
__cuda_local_var_43407_292_non_const_sum_time += (((__cuda_local_var_43173_15_non_const_ts)[(j + 1)]) - ((__cuda_local_var_43173_15_non_const_ts)[j])); __cuda_local_var_43407_319_non_const_max_time = ((__T2285 = ((__cuda_local_var_43173_15_non_const_ts)[(j + 1)])) , (umax(__cuda_local_var_43407_319_non_const_max_time, __T2285))); __cuda_local_var_43407_342_non_const_min_time = ((__T2286 = ((__cuda_local_var_43173_15_non_const_ts)[j])) , (umin(__cuda_local_var_43407_342_non_const_min_time, __T2286))); ((__cuda_local_var_43407_256_non_const_histogram)[((((__cuda_local_var_43173_15_non_const_ts)[(j + 1)]) - ((__cuda_local_var_43173_15_non_const_ts)[j])) / 256U)])++; } } __cuda_local_var_43407_365_non_const_sum_max_time += (__cuda_local_var_43407_319_non_const_max_time - __cuda_local_var_43407_342_non_const_min_time); } } __T2284:; if (__cuda_local_var_43407_388_non_const_failed) { printf(((const char *)"    %2d warp%c (%3d thread%c)  failed."), (((__cuda_local_var_43178_11_non_const_Db.x) + 31U) / 32U), ((int)(((__cuda_local_var_43178_11_non_const_Db.x) >= 64U) ? ((char)115) : ((char)32))), (__cuda_local_var_43178_11_non_const_Db.x), ((int)(((__cuda_local_var_43178_11_non_const_Db.x) > 1U) ? ((char)115) : ((char)32)))); } else  { printf(((const char *)"    %2d warp%c (%3d thr) %9u clk (%.3f clk/warp, %.3f ops/clk) "), (((__cuda_local_var_43178_11_non_const_Db.x) + 31U) / 32U), ((int)(((__cuda_local_var_43178_11_non_const_Db.x) >= 64U) ? ((char)115) : ((char)32))), (__cuda_local_var_43178_11_non_const_Db.x), __cuda_local_var_43407_365_non_const_sum_max_time, (((((double)__cuda_local_var_43407_292_non_const_sum_time) / (200.0)) / (256.0)) / ((double)(((__cuda_local_var_43178_11_non_const_Db.x) + 31U) / 32U))), (((51200.0) * ((double)(__cuda_local_var_43178_11_non_const_Db.x))) / ((double)__cuda_local_var_43407_365_non_const_sum_max_time))); printf(((const char *)"  Histogram { ")); {  int i;
# 462 "pipeline.cu"
i = 0; for (; (i < 1024); i++) { if (((__cuda_local_var_43407_256_non_const_histogram)[i]) != 0U) { printf(((const char *)"(%d: %d) "), i, ((__cuda_local_var_43407_256_non_const_histogram)[i])); } } } printf(((const char *)"}")); } printf(((const char *)"\n")); } printf(((const char *)"\n")); } while (0);
printf(((const char *)"\n"));


printf(((const char *)"Trying various combinations of MUL and MAD to test dual issue:\n"));
do {  enum cudaError __cuda_local_var_43412_165_non_const_error;
# 467 "pipeline.cu"
 unsigned __cuda_local_var_43412_383_non_const_min_t;
# 467 "pipeline.cu"
 unsigned __cuda_local_var_43412_403_non_const_max_t;
# 467 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MUL_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_MUL_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43412_165_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43412_165_non_const_error))); goto __T2287; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43412_383_non_const_min_t = 4294967295U; __cuda_local_var_43412_403_non_const_max_t = 0U; {  int i;
# 467 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2288;
 unsigned __T2289;
# 467 "pipeline.cu"
__cuda_local_var_43412_383_non_const_min_t = ((__T2288 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43412_383_non_const_min_t, __T2288))); __cuda_local_var_43412_403_non_const_max_t = ((__T2289 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43412_403_non_const_max_t, __T2289))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43412_403_non_const_max_t - __cuda_local_var_43412_383_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43412_403_non_const_max_t - __cuda_local_var_43412_383_non_const_min_t)))); } while (0); __T2287:;
do {  enum cudaError __cuda_local_var_43413_165_non_const_error;
# 468 "pipeline.cu"
 unsigned __cuda_local_var_43413_383_non_const_min_t;
# 468 "pipeline.cu"
 unsigned __cuda_local_var_43413_403_non_const_max_t;
# 468 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MAD_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z18K_MAD_FLOAT_DEP128PjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43413_165_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43413_165_non_const_error))); goto __T2290; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43413_383_non_const_min_t = 4294967295U; __cuda_local_var_43413_403_non_const_max_t = 0U; {  int i;
# 468 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2291;
 unsigned __T2292;
# 468 "pipeline.cu"
__cuda_local_var_43413_383_non_const_min_t = ((__T2291 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43413_383_non_const_min_t, __T2291))); __cuda_local_var_43413_403_non_const_max_t = ((__T2292 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43413_403_non_const_max_t, __T2292))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43413_403_non_const_max_t - __cuda_local_var_43413_383_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43413_403_non_const_max_t - __cuda_local_var_43413_383_non_const_min_t)))); } while (0); __T2290:;
do {  enum cudaError __cuda_local_var_43414_145_non_const_error;
# 469 "pipeline.cu"
 unsigned __cuda_local_var_43414_363_non_const_min_t;
# 469 "pipeline.cu"
 unsigned __cuda_local_var_43414_383_non_const_max_t;
# 469 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = 512U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("KMAD_MUL"))); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (__device_stub__Z8KMAD_MULPjS_ffi(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_43414_145_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43414_145_non_const_error))); goto __T2293; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_43414_363_non_const_min_t = 4294967295U; __cuda_local_var_43414_383_non_const_max_t = 0U; {  int i;
# 469 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_43178_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2294;
 unsigned __T2295;
# 469 "pipeline.cu"
__cuda_local_var_43414_363_non_const_min_t = ((__T2294 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umin(__cuda_local_var_43414_363_non_const_min_t, __T2294))); __cuda_local_var_43414_383_non_const_max_t = ((__T2295 = ((__cuda_local_var_43173_15_non_const_ts)[i])) , (umax(__cuda_local_var_43414_383_non_const_max_t, __T2295))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_43414_383_non_const_max_t - __cuda_local_var_43414_363_non_const_min_t), (((double)((__cuda_local_var_43178_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_43414_383_non_const_max_t - __cuda_local_var_43414_363_non_const_min_t)))); } while (0); __T2293:;
printf(((const char *)"\n"));



printf(((const char *)"Measuring latency of syncthreads with multiple warps running:\n")); {
 int i;
# 475 "pipeline.cu"
i = 1; for (; (i <= 16); i++)
{
printf(((const char *)"%d warps: "), i);
do {  enum cudaError __cuda_local_var_43423_115_non_const_error;
# 478 "pipeline.cu"
(__cuda_local_var_43178_11_non_const_Db.x) = ((unsigned)(i * 32)); (cudaConfigureCall(__cuda_local_var_43179_11_non_const_Dg, __cuda_local_var_43178_11_non_const_Db, 0UL, ((struct CUstream_st *)0LL))) ? ((void)0) : (K_SYNC_UINT_DEP128(__cuda_local_var_43174_16_non_const_d_ts, __cuda_local_var_43175_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SYNC_UINT_DEP128"))); if (((int)(__cuda_local_var_43423_115_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_43423_115_non_const_error))); goto __T2296; } cudaMemcpy(((void *)(__cuda_local_var_43173_15_non_const_ts)), ((const void *)__cuda_local_var_43174_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0])), (((double)(((__cuda_local_var_43173_15_non_const_ts)[1]) - ((__cuda_local_var_43173_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2296:;
} }

cudaFree(((void *)__cuda_local_var_43174_16_non_const_d_ts));
cudaFree(((void *)__cuda_local_var_43175_16_non_const_d_out)); 

}
static void __sti___16_pipeline_cpp1_ii_40ef163b(void) {   }

#include "pipeline.cudafe1.stub.c"
